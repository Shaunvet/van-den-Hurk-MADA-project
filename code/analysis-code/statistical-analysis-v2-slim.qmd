---
title: "Processing CDC hypertension and CDV Mortality disease data from adults in the USA exploratory analysis script"
format: html
editor: visual
---

This should be the third and final file to run when reproducing the full analysis. Thereafter you will get results in the manuscript/supplementary.

# Setup

```{r setup}
#load needed packages. make sure they are installed.
#install.packages("gt")
#install.packages("emmeans")
library(ggplot2) #for plotting
library(broom) #for cleaning up output from lm()
library(here) #for data loading/saving
library(tidyverse)
library(tidymodels)
library(gt)
library(stringr)
library(patchwork)
library(emmeans)
library(sf) #for geospatial analysis
library(spdep)
library(spatialreg)
library(vip) # For variable importance plots
library(dplyr)
library(tidytext)
library(forcats)
library(webshot2)  # for gt image export
library(ggpubr)

```

```{r}
#path to data
data_location <- here::here("data","processed-data","eda_outputs.rds")

#load data. 
final_processed_data <- readRDS(data_location)

# Extract key datasets
processed_data_no_percent <- final_processed_data[["processed_data_no_percent"]]
county_race_sex <- final_processed_data[["county_race_sex"]]
county_race <- final_processed_data[["county_race"]]
county_sex <- final_processed_data[["county_sex"]]
county_overall <- final_processed_data[["county_overall"]]

```

# Data fitting/statistical analysis

Summary statistics of baseline mortality by race/ethnicity, sex, and age group are provided later (between Aim 3 and 4) to contextualize subsequent slope estimates.

## Aim 1: Temporal Trends by Age Group

We evaluated national trends in mortality rates over time using multiple modeling approaches. These included a simple linear regression, generalized linear models (GLMs) with race, sex, and age group predictors, and interaction models to assess differential trends. All models assumed a Gaussian distribution and were fit using complete national data.

### 1.1 Linear Model - Overall Mortality over time

Fit a basic linear regression to estimate overall trend in mortality over time

```{r}
# Checking the relationship between mortality and year
lm_model_year <- lm(mortalities ~ Year, data = county_overall)
lm_results_year <- broom::tidy(lm_model_year)

# Display and save the regression results
print(lm_results_year)
invisible(saveRDS(lm_results_year, file = here::here("results", "output", "statistical-analysis", "lm_results_year.rds")))

# Extract model fit statistics
model_fit_lm <- broom::glance(lm_model_year) %>%
  dplyr::mutate(model = "LM: National Year Trend")

# Save as table
invisible(saveRDS(model_fit_lm, here::here("results", "tables", "model_fit_national.rds")))

# Plot linear regression results
lm_plot_year <- ggplot(county_overall, aes(x = Year, y = mortalities)) +
  geom_point(alpha = 0.5) +
  geom_smooth(method = "lm", se = FALSE, color = "red") +
  theme_minimal() +
  labs(title = "Linear Regression: Mortality Rates Over Time", x = "Year", y = "Mortality Rate")

print(lm_plot_year)
invisible(ggsave(here::here("results", "figures", "lm_plot_year.png"), plot = lm_plot_year))

```

This model provides a first look at overall temporal trends in mortality rates.

The linear regression model estimated a modest but statistically significant annual increase in national hypertension-related CVD mortality rates between 2000 and 2019 (slope = 1.40, p \< 2.2e-16). However, as shown in the plot, the fitted trend line is visually flat due to the scale and large variation in county-level rates. The intercept value is not directly interpretable, but reflects the expected mortality rate at year zero in the model's coding. Despite the statistically significant trend, the magnitude of change is small relative to the observed range, suggesting that national mortality rates remained relatively stable over time. This model does not account for age or other demographic factors, motivating the more detailed modeling in the next section.

### 1.2 GLM: Race and Sex as predictors GLM with race and sex as additive predictors to assess overall differences in mortality rates

```{r}
# Examining multiple predictors
glm_model <- glm(mortalities ~ Year + race_ethnicity + sex, data = county_race_sex, family = gaussian())
glm_results <- broom::tidy(glm_model)

# Display and save the GLM results
print(glm_results)
invisible(saveRDS(glm_results, file = here::here("results", "output", "statistical-analysis", "glm_results.rds")))


# Plot GLM predictions
  county_race_sex$predicted_mortalities <- predict(glm_model, type = "response")
  glm_race_sex_plot <- ggplot(county_race_sex, aes(x = Year, y = predicted_mortalities, color = race_ethnicity)) +
    geom_line(size = 1) +
    theme_minimal() +
    labs(title = "GLM Predictions: Mortality Rates by Year and Race/Ethnicity", x = "Year", y = "Predicted Mortality Rate", color = "Race/Ethnicity") +
    scale_x_continuous(breaks = seq(min(county_race_sex$Year, na.rm = TRUE), max(county_race_sex$Year, na.rm = TRUE), by = 5)) +
    theme(legend.position = "right", legend.text = element_text(size = 10), legend.key.size = unit(0.4, "cm"), legend.spacing.y = unit(0.2, "cm"), axis.text.x = element_text(angle = 45, hjust = 1))
  
  print(glm_race_sex_plot)
  invisible(ggsave(here::here("results", "figures", "glm_race_sex_plot.png"), plot = glm_race_sex_plot))
  
```

```{r}
# Examining multiple predictors
glm_model <- glm(mortalities ~ Year + race_ethnicity + sex, data = county_race_sex, family = gaussian())
glm_results <- broom::tidy(glm_model)

# Display and save the GLM results
print(glm_results)
invisible(saveRDS(glm_results, file = here::here("results", "output", "statistical-analysis", "glm_results.rds")))

# Add predicted values
county_race_sex$predicted_mortalities <- predict(glm_model, type = "response")

# Filter out "Overall" race_ethnicity values before plotting
plot_data <- county_race_sex %>%
  filter(race_ethnicity != "Overall")

# Create polished plot
glm_race_sex_plot <- ggplot(plot_data, aes(x = Year, y = predicted_mortalities, color = race_ethnicity)) +
  geom_line(size = 1.2) +
  theme_minimal(base_size = 12) +
  labs(
    title = "GLM Predictions: Mortality Rates by Year and Race/Ethnicity",
    x = "Year",
    y = "Predicted Mortality Rate (per 100,000)",
    color = "Race/Ethnicity"
  ) +
  scale_x_continuous(
    breaks = seq(min(plot_data$Year, na.rm = TRUE), max(plot_data$Year, na.rm = TRUE), by = 5)
  ) +
  scale_color_discrete(labels = function(x) str_wrap(x, width = 20)) +
  theme(
    legend.position = "right",
    legend.text = element_text(size = 10),
    legend.title = element_text(size = 11),
    legend.key.size = unit(0.4, "cm"),
    legend.spacing.y = unit(0.2, "cm"),
    axis.text.x = element_text(angle = 45, hjust = 1),
    plot.title = element_text(face = "bold", size = 13, hjust = 0.5))

# Display plot
print(glm_race_sex_plot)

# Save figure
ggsave(
  here::here("results", "figures", "glm_race_sex_plot.png"),
  plot = glm_race_sex_plot,
  width = 7.5,
  height = 5.5,
  dpi = 300)


```

```{r}

# Fit GLM model (no interaction)
glm_model <- glm(mortalities ~ Year + race_ethnicity + sex, data = county_race_sex, family = gaussian())

# Save tidy model output
glm_results <- broom::tidy(glm_model)
print(glm_results)
invisible(saveRDS(glm_results, file = here::here("results", "output", "statistical-analysis", "glm_results.rds")))

# Predict mortality values from model
county_race_sex$predicted_mortalities <- predict(glm_model, type = "response")

# Remove "Overall" for plotting
filtered_data <- county_race_sex %>%
  filter(race_ethnicity != "Overall")

# Summarize observed means
observed_summary <- filtered_data %>%
  group_by(Year, race_ethnicity) %>%
  summarise(
    observed_mean = mean(mortalities, na.rm = TRUE),
    .groups = "drop")

# Summarize predicted means
predicted_summary <- filtered_data %>%
  group_by(Year, race_ethnicity) %>%
  summarise(
    predicted_mean = mean(predicted_mortalities, na.rm = TRUE),
    .groups = "drop")

# Join observed and predicted for plotting
plot_data <- left_join(observed_summary, predicted_summary, by = c("Year", "race_ethnicity"))

# Create overlay plot
glm_race_sex_plot <- ggplot(plot_data, aes(x = Year, color = race_ethnicity)) +
  geom_point(aes(y = observed_mean), size = 1.5, alpha = 0.6) +
  geom_line(aes(y = predicted_mean), size = 1.2) +
  theme_minimal(base_size = 12) +
  labs(
    title = "Observed and Predicted Mortality Rates by Race/Ethnicity (2000–2019)",
    x = "Year",
    y = "Mortality Rate (per 100,000)",
    color = "Race/Ethnicity"
  ) +
  scale_x_continuous(
    breaks = seq(min(plot_data$Year, na.rm = TRUE), max(plot_data$Year, na.rm = TRUE), by = 5)
  ) +
  scale_color_discrete(labels = function(x) str_wrap(x, width = 20)) +
  theme(
    plot.title = element_text(size = 13, face = "bold", hjust = 0.5),
    legend.position = "right",
    legend.title = element_text(size = 11),
    legend.text = element_text(size = 10),
    axis.text.x = element_text(angle = 45, hjust = 1),
    legend.key.size = unit(0.4, "cm"),
    legend.spacing.y = unit(0.2, "cm"))

# Display
print(glm_race_sex_plot)

# Save plot (overwrite previous)
ggsave(
  here::here("results", "figures", "glm_race_sex_plot.png"),
  plot = glm_race_sex_plot,
  width = 7.5,
  height = 5.5,
  dpi = 300)


```

The GLM including race/ethnicity and sex as predictors highlights large disparities in predicted mortality rates. Black populations had the highest predicted rates, significantly higher than all other groups (e.g., β = 205.8, p \< 2e-16). Hispanic and Asian/Pacific Islander groups had lower mortality, though the Asian effect was not significant (p = 0.35). Males also showed significantly higher mortality than females (β = 20.3, p \< 2e-16). Notably, the “Overall” category behaves inconsistently in plots due to it being modeled as a separate group rather than a true average, likely affected by unmodeled age variation. This supports the need to model interactions and stratify further by age.

### 1.3 GLM: Year by Race interaction model: Fit GLM including interaction between year and race to examine race-specific trends over time

```{r}

#explore whether interactions exist between year and race/sex:

glm_model_interaction <- glm(mortalities ~ Year * race_ethnicity + sex, data = county_race_sex, family = gaussian())

glm_results_interaction <- broom::tidy(glm_model_interaction)
print(glm_results_interaction)

invisible(saveRDS(glm_results_interaction, file = here::here("results", "output", "statistical-analysis", "glm_results_interaction.rds")))


# Plot the interaction model results
county_race_sex$predicted_mortalities_interaction <- predict(glm_model_interaction, type = "response")
glm_interaction_plot <- ggplot(county_race_sex, aes(x = Year, y = predicted_mortalities_interaction, color = race_ethnicity)) +
  geom_line(size = 1) +
  theme_minimal() +
  labs(title = "GLM Interaction Model: Mortality Trends by Year and Race", x = "Year", y = "Predicted Mortality Rate", color = "Race/Ethnicity") +
  scale_x_continuous(breaks = seq(min(county_race_sex$Year, na.rm = TRUE), max(county_race_sex$Year, na.rm = TRUE), by = 5)) +
  theme(legend.position = "right", legend.text = element_text(size = 11), legend.key.size = unit(0.4, "cm"), legend.spacing.y = unit(0.2, "cm"), axis.text.x = element_text(angle = 45, hjust = 1))

print(glm_interaction_plot)
invisible(ggsave(here::here("results", "figures", "glm_interaction_plot.png"), plot = glm_interaction_plot))

invisible(saveRDS(county_race_sex, file = here::here("results", "output", "statistical-analysis", "county_race_sex_with_preds.rds")))
```

```{r}
# Explore whether interactions exist between year and race/sex
glm_model_interaction <- glm(
  mortalities ~ Year * race_ethnicity + sex,
  data = county_race_sex,
  family = gaussian())

glm_results_interaction <- broom::tidy(glm_model_interaction)
print(glm_results_interaction)

invisible(saveRDS(
  glm_results_interaction,
  file = here::here("results", "output", "statistical-analysis", "glm_results_interaction.rds")))

# Add interaction predictions
county_race_sex$predicted_mortalities_interaction <- predict(glm_model_interaction, type = "response")

# Filter out "Overall" before plotting
plot_data <- county_race_sex %>%
  filter(race_ethnicity != "Overall")

# Create clean interaction plot
glm_interaction_plot <- ggplot(plot_data, aes(x = Year, y = predicted_mortalities_interaction, color = race_ethnicity)) +
  geom_line(size = 1.2) +
  theme_minimal(base_size = 12) +
  labs(
    title = "GLM Interaction Model: Mortality Trends by Year and Race/Ethnicity",
    x = "Year",
    y = "Predicted Mortality Rate (per 100,000)",
    color = "Race/Ethnicity"
  ) +
  scale_x_continuous(
    breaks = seq(min(plot_data$Year, na.rm = TRUE), max(plot_data$Year, na.rm = TRUE), by = 5)
  ) +
  scale_color_discrete(labels = function(x) str_wrap(x, width = 20)) +
  theme(
    legend.position = "right",
    legend.text = element_text(size = 10),
    legend.title = element_text(size = 11),
    legend.key.size = unit(0.4, "cm"),
    legend.spacing.y = unit(0.2, "cm"),
    axis.text.x = element_text(angle = 45, hjust = 1),
    plot.title = element_text(size = 13, face = "bold", hjust = 0.5))

# Display plot
print(glm_interaction_plot)

# Save cleaned image
ggsave(
  here::here("results", "figures", "glm_interaction_plot.png"),
  plot = glm_interaction_plot,
  width = 7.5,
  height = 5.5,
  dpi = 300)

# Save updated data
invisible(saveRDS(county_race_sex,file = here::here("results", "output", "statistical-analysis", "county_race_sex_with_preds.rds")))

```

```{r}
# Fit interaction model
glm_model_interaction <- glm(
  mortalities ~ Year * race_ethnicity + sex,
  data = county_race_sex,
  family = gaussian())

# Save model results
glm_results_interaction <- broom::tidy(glm_model_interaction)
print(glm_results_interaction)
invisible(saveRDS(
  glm_results_interaction,
  file = here::here("results", "output", "statistical-analysis", "glm_results_interaction.rds")))

# Add predicted values to dataset
county_race_sex$predicted_mortalities_interaction <- predict(glm_model_interaction, type = "response")

# Filter out "Overall" before plotting
filtered_data <- county_race_sex %>%
  filter(race_ethnicity != "Overall")

# Summarize observed data by group and year
observed_summary <- filtered_data %>%
  group_by(Year, race_ethnicity) %>%
  summarise(observed_mean = mean(mortalities, na.rm = TRUE), .groups = "drop")

# Summarize predicted means
predicted_summary <- filtered_data %>%
  group_by(Year, race_ethnicity) %>%
  summarise(predicted_mean = mean(predicted_mortalities_interaction, na.rm = TRUE), .groups = "drop")

# Combine both summaries
plot_data <- left_join(observed_summary, predicted_summary, by = c("Year", "race_ethnicity"))

# Create overlay plot
glm_interaction_plot <- ggplot(plot_data, aes(x = Year, color = race_ethnicity)) +
  geom_point(aes(y = observed_mean), size = 1.5, alpha = 0.6) +  # Observed
  geom_line(aes(y = predicted_mean), size = 1.2) +               # Predicted
  theme_minimal(base_size = 12) +
  labs(
    title = "Observed and Predicted Mortality Rates by Race/Ethnicity (2000–2019)",
    x = "Year",
    y = "Mortality Rate (per 100,000)",
    color = "Race/Ethnicity"
  ) +
  scale_x_continuous(
    breaks = seq(min(plot_data$Year, na.rm = TRUE), max(plot_data$Year, na.rm = TRUE), by = 5)
  ) +
  scale_color_discrete(labels = function(x) str_wrap(x, width = 20)) +
  theme(
    plot.title = element_text(size = 13, face = "bold", hjust = 0.5),
    legend.position = "right",
    legend.title = element_text(size = 11),
    legend.text = element_text(size = 10),
    axis.text.x = element_text(angle = 45, hjust = 1),
    legend.key.size = unit(0.4, "cm"),
    legend.spacing.y = unit(0.2, "cm"))

# Display updated plot
print(glm_interaction_plot)

# Save image
ggsave(
  here::here("results", "figures", "glm_interaction_plot.png"),
  plot = glm_interaction_plot,
  width = 7.5,
  height = 5.5,
  dpi = 300)

# Save updated dataset
invisible(saveRDS(
  county_race_sex,
  file = here::here("results", "output", "statistical-analysis", "county_race_sex_with_preds.rds")))



```

Including an interaction between year and race revealed significantly divergent temporal trends. Mortality rates among Black individuals showed the steepest annual decline (β = –7.06, p \< 0.001), while American Indian and Alaska Native (AI/AN) populations exhibited the largest annual increase (β for year = 3.38, p \< 0.001, with positive main effect and significant negative interactions for other groups). Asian and Pacific Islander, Hispanic, and White populations also showed declining trends, though to a lesser extent. These results highlight substantial heterogeneity in how hypertension-related CVD mortality changed over time across racial/ethnic groups.

Given known age-related disparities in cardiovascular risk, we next modeled mortality trends across age groups. This model assesses whether older adults experienced steeper or flatter trajectories over time.

### 1.4: GLM: Year by Age group

GLM with interaction between year and age group to examine differential temporal trends

```{r}
# GLM with interaction: does time trend differ by age group?
glm_age_group <- glm(mortalities ~ Year * age_group, 
                     data = processed_data_no_percent,
                     family = gaussian())

# Tidy results for review
glm_age_group_results <- broom::tidy(glm_age_group)
print(glm_age_group_results)

# Save results
invisible(saveRDS(glm_age_group_results, file = here::here("results", "output", "statistical-analysis", "glm_age_group_results.rds")))

# Extract model fit statistics
model_fit_agegroup <- broom::glance(glm_age_group) %>%
  dplyr::mutate(model = "GLM: Age Group")

# Save as table
invisible(saveRDS(model_fit_agegroup, here::here("results", "tables", "model_fit_agegroup.rds")))


# Add predicted values
processed_data_no_percent$predicted_glm_age <- predict(glm_age_group, type = "response")

# Plot actual vs predicted for each age group
glm_age_plot <- ggplot(processed_data_no_percent, 
                       aes(x = Year, y = mortalities, color = age_group)) +
  geom_point(alpha = 0.4) +
  geom_line(aes(y = predicted_glm_age), size = 1.2) +
  theme_minimal() +
  labs(title = "Predicted Mortality Trends by Age Group",
       subtitle = "From GLM: mortalities ~ Year * age_group",
       x = "Year", y = "Mortality Rate") +
  scale_color_brewer(palette = "Dark2")

print(glm_age_plot)

# Save plot
invisible(ggsave(here::here("results", "figures", "glm_age_plot.png"), 
       plot = glm_age_plot, width = 9, height = 6))

```

This model identifies age-specific trends.Mortality among individuals aged 65+ remains substantially higher and shows modest increases, while younger age groups have lower, flatter trends. Including an interaction between year and age group revealed that mortality rates are substantially higher in the 65+ age group across all years. While both age groups show increasing mortality over time, the slope is significantly steeper for older adults (interaction term β = 0.224, p \< 0.001), suggesting accelerated increases in mortality among those aged 65 and older.

### 1.5: Slope comparison by Age group

Comparing slopes using the emmeans function. Use estimated marginal trends (emtrends) to compare yearly slope by age group.

```{r}
# Get slope (trend) estimates for Year, stratified by age group
em_trends_age <- emtrends(glm_age_group, ~ age_group, var = "Year")

# View summary
summary(em_trends_age)
em_trends_age


# Format slope estimates for reporting
slope_table_age_fmt <- as.data.frame(summary(em_trends_age)) %>%
  dplyr::mutate(
    Estimate = round(Year.trend, 3),
    CI = paste0(round(lower.CL, 2), "–", round(upper.CL, 2)),
    SE = round(SE, 3)) %>%
  dplyr::select(`Age Group` = age_group, Estimate, SE, CI)

# Save as manuscript-ready table
invisible(saveRDS(slope_table_age_fmt, here::here("results", "tables", "slope_table_agegroup_fmt.rds")))


# Create and save polished PNG table for manuscript
slope_table_agegroup_gt <- slope_table_age_fmt %>%
  gt() %>%
  tab_header(
    title = "Estimated Annual Increase in Mortality by Age Group",
    subtitle = "Derived from GLM with Year × Age Group Interaction"
  ) %>%
  fmt_number(columns = c(Estimate, SE), decimals = 3) %>%
  cols_label(
    `Age Group` = "Age Group",
    Estimate = "Slope",
    SE = "Standard Error",
    CI = "95% CI"
  ) %>%
  opt_table_font(font = google_font("Roboto")) %>%
  tab_options(table.width = pct(80),             # shrink width
  table.font.size = "12",         # shrink font
  data_row.padding = px(2),          # reduce row height
  column_labels.font.weight = "bold")

gtsave(
  slope_table_agegroup_gt,
  filename = here::here("results", "tables", "slope_table_agegroup.png"))

slope_table_agegroup_gt

```

```{r}
# compare trends between groups (pairwise contrast)
slope_contrast <- contrast(em_trends_age, method = "pairwise")
summary(slope_contrast)

# Save
invisible(saveRDS(em_trends_age, file = here::here("results", "output", "statistical-analysis", "emtrends_age_group.rds")))
invisible(saveRDS(slope_contrast, file = here::here("results", "output", "statistical-analysis", "slope_contrast_age_group.rds")))


# Format pairwise slope differences for age group
slope_contrast_age_fmt <- as.data.frame(summary(slope_contrast, infer = c(TRUE, TRUE))) %>%
  dplyr::mutate(
    Estimate = round(estimate, 3),
    CI = paste0(round(lower.CL, 2), "–", round(upper.CL, 2)),
    SE = round(SE, 3),
    p_value = signif(p.value, 3)
  ) %>%
  dplyr::select(Contrast = contrast, Estimate, SE, CI, p_value)

# Save formatted contrast table
invisible(saveRDS(slope_contrast_age_fmt, here::here("results", "tables", "slope_contrast_agegroup_fmt.rds")))

slope_contrast_age_fmt

# Convert emtrends object to data frame
em_trend_df <- as.data.frame(summary(em_trends_age))

# Create horizontal bar plot with fixed x-axis breaks
slope_plot_agegroup <- ggplot(em_trend_df, aes(x = Year.trend, y = age_group)) +
  geom_col(fill = "#2C77B0", width = 0.5) +
  geom_errorbarh(aes(xmin = Year.trend - 1.96 * SE,
                     xmax = Year.trend + 1.96 * SE),
                 height = 0.15, color = "gray40") +
  geom_vline(xintercept = 0, linetype = "dashed", color = "gray50") +
  scale_x_continuous(
    breaks = seq(0, 1.5, by = 0.25),
    limits = c(0, 1.5)
  ) +
  labs(
    title = "Estimated Annual Mortality Rate Change by Age Group",
    subtitle = "Point estimates and 95% confidence intervals",
    x = "Estimated Slope (Yearly Change)",
    y = "Age Group"
  ) +
  theme_minimal(base_size = 13) +
  theme(
    plot.title = element_text(face = "bold", size = 14, margin = margin(b = 6)),
    plot.subtitle = element_text(size = 11, margin = margin(b = 10)),
    axis.text = element_text(size = 12),
    panel.grid.major.y = element_blank())

# Display plot
slope_plot_agegroup

# Save figure to manuscript folder
invisible(ggsave(filename = here::here("results", "figures", "slope_plot_age_group.png"),
  plot = slope_plot_agegroup,
  width = 9, height = 6, dpi = 300))

# Save RDS for reproducibility
invisible(saveRDS(slope_plot_agegroup, file = here::here("results", "output", "statistical-analysis", "slope_plot_age_group.rds")))

```

Using estimated marginal trends, we formally test whether the yearly rate of change differs between age groups. Older adults (65+) show a significantly steeper upward trend compared to younger adults.

Estimated yearly changes in mortality rates were significantly higher for adults aged 65+ (slope = 1.26, 95% CI: 1.18–1.34) compared to those aged 35–64 (slope = 1.04, 95% CI: 0.96–1.12). The difference in slope between age groups was statistically significant (difference = -0.224, p \< 0.001), indicating a steeper rise in mortality among older adults.

Overall, the results from Aim 1 highlight that age is a significant modifier of temporal trends in hypertension-related cardiovascular mortality. While the overall trend appeared stable at the national level, subgroup analyses revealed that mortality has been increasing more sharply among older adults, and certain racial/ethnic groups show distinct patterns of change over time. These findings justify further exploration of disparities and spatial variation in subsequent aims.

## Aim 2: Spatial Analysis of Hypertension Mortality Rates

## Evaluating spatial distribution and clustering patterns

Evaluating spatial patterns for mortality data for all races together and individually.

### 2.1: Static maps by Race:

Converting county data to spatial object using longitude/latitude. Creating static spatial maps of county-level mortality rates by race/ethnicity, visualized using spatial coordinates. These provide an overview of geographic variation across U.S. counties.

```{r}
#Convert dataset to an SF spatial object
county_race_sex_sf <- county_race_sex %>%
  st_as_sf(coords = c("X_long", "Y_lat"), crs = 4326, remove = FALSE)

# Spatial plot for all races
spatial_plot_all <- ggplot() +
  geom_sf(data = county_race_sex_sf, aes(color = mortalities), size = 0.7) +
  scale_color_viridis_c() +
  theme_minimal() +
  labs(title = "Spatial Distribution of Mortality Rates (All Races)", x = "Longitude", y = "Latitude", color = "Mortality Rate")

print(spatial_plot_all)
invisible(ggsave(here::here("results", "figures", "spatial_plot_all.png"), plot = spatial_plot_all))

# Spatial plot for Black race
black_race_sf <- county_race_sex_sf %>% filter(race_ethnicity == "Black")
black_spatial_plot <- ggplot() +
  geom_sf(data = black_race_sf, aes(color = mortalities), size = 0.7) +
  scale_color_viridis_c() +
  theme_minimal() +
  labs(title = "Spatial Distribution of Mortality Rates (Black Race)", x = "Longitude", y = "Latitude", color = "Mortality Rate")

print(black_spatial_plot)
invisible(ggsave(here::here("results", "figures", "black_spatial_plot.png"), plot = black_spatial_plot))

# Spatial plot for White race
white_race_sf <- county_race_sex_sf %>% filter(race_ethnicity == "White")
white_spatial_plot <- ggplot() +
  geom_sf(data = white_race_sf, aes(color = mortalities), size = 0.7) +
  scale_color_viridis_c() +
  theme_minimal() +
  labs(title = "Spatial Distribution of Mortality Rates (White Race)", x = "Longitude", y = "Latitude", color = "Mortality Rate")

print(white_spatial_plot)
invisible(ggsave(here::here("results", "figures", "white_spatial_plot.png"), plot = white_spatial_plot))

# Spatial plot for Hispanic race
hispanic_sf <- county_race_sex_sf %>% filter(race_ethnicity == "Hispanic")
hispanic_spatial_plot <- ggplot() +
  geom_sf(data = hispanic_sf, aes(color = mortalities), size = 0.7) +
  scale_color_viridis_c() +
  theme_minimal() +
  labs(title = "Spatial Distribution of Mortality Rates (Hispanic)", x = "Longitude", y = "Latitude", color = "Mortality Rate")

print(hispanic_spatial_plot)
invisible(ggsave(here::here("results", "figures", "hispanic_spatial_plot.png"), plot = hispanic_spatial_plot))


# Spatial plot for American Indian and Alaska Native race
native_sf <- county_race_sex_sf %>% filter(race_ethnicity == "American Indian and Alaska Native")
native_spatial_plot <- ggplot() +
  geom_sf(data = native_sf, aes(color = mortalities), size = 0.7) +
  scale_color_viridis_c() +
  theme_minimal() +
  labs(title = "Spatial Distribution of Mortality Rates\n(American Indian and Alaska Native)", x = "Longitude", y = "Latitude", color = "Mortality Rate")

print(native_spatial_plot)
invisible(ggsave(here::here("results", "figures", "native_spatial_plot.png"), plot = native_spatial_plot))


# Spatial plot for Asian and Pacific Islander race
asian_sf <- county_race_sex_sf %>% filter(race_ethnicity == "Asian and Pacific Islander")
asian_spatial_plot <- ggplot() +
  geom_sf(data = asian_sf, aes(color = mortalities), size = 0.7) +
  scale_color_viridis_c() +
  theme_minimal() +
  labs(title = "Spatial Distribution of Mortality Rates\n(Asian and Pacific Islander)", x = "Longitude", y = "Latitude", color = "Mortality Rate")

print(asian_spatial_plot)
invisible(ggsave(here::here("results", "figures", "asian_spatial_plot.png"), plot = asian_spatial_plot))

```

```{r}
# Convert to sf object
county_race_sex_sf <- county_race_sex %>%
  st_as_sf(coords = c("X_long", "Y_lat"), crs = 4326, remove = FALSE)

# Create a reusable theme
spatial_theme <- theme_minimal(base_size = 12) +
  theme(
    plot.title = element_text(hjust = 0.5, size = 13, face = "bold"),
    axis.text = element_text(size = 10),
    axis.title = element_text(size = 11),
    legend.text = element_text(size = 10),
    legend.title = element_text(size = 10)
  )

# 1. All races
spatial_plot_all <- ggplot() +
  geom_sf(data = county_race_sex_sf, aes(color = mortalities), size = 0.7) +
  scale_color_viridis_c() +
  labs(title = "Spatial Distribution of Mortality Rates – All Races", x = "Longitude", y = "Latitude", color = "Mortality Rate") +
  spatial_theme
ggsave(here::here("results", "figures", "spatial_plot_all.png"), spatial_plot_all, width = 7, height = 5, dpi = 320)

spatial_plot_all

# 2. Black
black_race_sf <- county_race_sex_sf %>% filter(race_ethnicity == "Black")
black_spatial_plot <- ggplot() +
  geom_sf(data = black_race_sf, aes(color = mortalities), size = 0.7) +
  scale_color_viridis_c() +
  labs(title = "Spatial Distribution of Mortality Rates – Black", x = "Longitude", y = "Latitude", color = "Mortality Rate") +
  spatial_theme
ggsave(here::here("results", "figures", "black_spatial_plot.png"), black_spatial_plot, width = 7, height = 5, dpi = 320)

black_spatial_plot

# 3. White
white_race_sf <- county_race_sex_sf %>% filter(race_ethnicity == "White")
white_spatial_plot <- ggplot() +
  geom_sf(data = white_race_sf, aes(color = mortalities), size = 0.7) +
  scale_color_viridis_c() +
  labs(title = "Spatial Distribution of Mortality Rates – White", x = "Longitude", y = "Latitude", color = "Mortality Rate") +
  spatial_theme
ggsave(here::here("results", "figures", "white_spatial_plot.png"), white_spatial_plot, width = 7, height = 5, dpi = 320)

white_spatial_plot

# 4. Hispanic
hispanic_sf <- county_race_sex_sf %>% filter(race_ethnicity == "Hispanic")
hispanic_spatial_plot <- ggplot() +
  geom_sf(data = hispanic_sf, aes(color = mortalities), size = 0.7) +
  scale_color_viridis_c() +
  labs(title = "Spatial Distribution of Mortality Rates – Hispanic", x = "Longitude", y = "Latitude", color = "Mortality Rate") +
  spatial_theme
ggsave(here::here("results", "figures", "hispanic_spatial_plot.png"), hispanic_spatial_plot, width = 7, height = 5, dpi = 320)

hispanic_spatial_plot

# 5. American Indian and Alaska Native
native_sf <- county_race_sex_sf %>% filter(race_ethnicity == "American Indian and Alaska Native")
native_spatial_plot <- ggplot() +
  geom_sf(data = native_sf, aes(color = mortalities), size = 0.7) +
  scale_color_viridis_c() +
  labs(title = "Spatial Distribution of Mortality Rates – American Indian and Alaska Native", x = "Longitude", y = "Latitude", color = "Mortality Rate") +
  spatial_theme
ggsave(here::here("results", "figures", "native_spatial_plot.png"), native_spatial_plot, width = 7, height = 5, dpi = 320)

native_spatial_plot

# 6. Asian and Pacific Islander
asian_sf <- county_race_sex_sf %>% filter(race_ethnicity == "Asian and Pacific Islander")
asian_spatial_plot <- ggplot() +
  geom_sf(data = asian_sf, aes(color = mortalities), size = 0.7) +
  scale_color_viridis_c() +
  labs(title = "Spatial Distribution of Mortality Rates – Asian and Pacific Islander", x = "Longitude", y = "Latitude", color = "Mortality Rate") +
  spatial_theme
ggsave(here::here("results", "figures", "asian_spatial_plot.png"), asian_spatial_plot, width = 10, height = 5, dpi = 320)

asian_spatial_plot

```

### 2.2 Combined spatial plot

Combining all spatial race-specific maps into a multi-panel figure.

```{r}
# Explicit spacing and margins
combined_spatial_plot <- (
  spatial_plot_all + theme(plot.margin = margin(10, 10, 10, 10)) |
  black_spatial_plot + theme(plot.margin = margin(10, 10, 10, 10))
) /
(
  white_spatial_plot + theme(plot.margin = margin(10, 10, 10, 10)) |
  hispanic_spatial_plot + theme(plot.margin = margin(10, 10, 10, 10))
) /
(
  native_spatial_plot + theme(plot.margin = margin(10, 10, 10, 10)) |
  asian_spatial_plot + theme(plot.margin = margin(10, 10, 10, 10))
)


ggsave(
  here::here("results", "figures", "combined_spatial_plot.png"),
  plot = combined_spatial_plot,
  width = 21,   # large print-friendly layout
  height = 15,
  dpi = 320
)

print(combined_spatial_plot)
```

These plots are best viewed as images outside of R due to size limits in R.

Static maps show clear geographic variation in hypertension-related CVD mortality. Black and White populations exhibit widespread mortality across the Southeast and Midwest, while Hispanic and Asian populations show more localized clusters, reflecting regional concentration and data availability. The highest mortality hotspots for American Indian and Alaska Native groups are found in the central U.S., consistent with known health disparities.

While visual maps provide insight into geographic differences in mortality, they do not quantify the extent of spatial clustering. To formally assess spatial autocorrelation, we next apply Global Moran’s I and Local Indicators of Spatial Association (LISA) statistics.

### Evaluating spatial clustering of Mortality Rates.

### 2.3: Global Moran’s I – All Races Combined

We will run a Global Morans analysis to evalaute spatial clustering using K-nearest neighbour clustering. We are looking at the full dataset here which is very computationally intensive. Thus we are setting the code to load the output, but if its not present (not saved) then it will run. We have saved the output in the large

Running Global Moran's I test to evaluate overall spatial autocorrelation.

```{r spatial-weights global-morans-i, message=FALSE}
# Define file paths for output objrects
knn_path <- here::here("results", "output", "knn_neighbors.rds") # Larger, reusable object
lw_path <- here::here("results", "output", "spatial_weights_list.rds") # Larger, reusable object
moran_path <- here::here("results", "output", "global_morans_i.rds") # Smaller, result-level output


#Reuse or compute spatial weights
#computing is very computationally intensive because we are usign the full dataset

#Check if neighbor and weight objects are already saved
if (file.exists(knn_path) && file.exists(lw_path)) {
   # Load saved spatial weights
  message("Reusing saved spatial weights and neighbors.")
  knn_nb <- readRDS(knn_path)
  lw <- readRDS(lw_path)
} else {
  message("Generating spatial weights from coordinates.")
coords <- st_coordinates(county_race_sex_sf)
knn_nb <- knn2nb(knearneigh(coords, k = 5)) # Create neighbors list - 5 nearest neighbours
lw <- nb2listw(knn_nb, style = "W") # Convert to spatial weights list

  # Save for reuse
  saveRDS(knn_nb, file = knn_path)
  saveRDS(lw, file = lw_path)}


# Global Moran’s I analysis
moran_result <- moran.test(county_race_sex_sf$mortalities, lw)
print(moran_result)

# Extract key statistics from Moran's I test
moran_table <- tibble::tibble(
  Region = "USA (All Counties)",
  Moran_I = round(moran_result$estimate[["Moran I statistic"]], 4),
  Expected_I = round(moran_result$estimate[["Expectation"]], 4),
  SD = round(moran_result$estimate[["Variance"]], 4),
  p_value = signif(moran_result$p.value, 3))

moran_table

# Save to results/tables
invisible(saveRDS(moran_table, here::here("results", "tables", "global_morans_i_summary.rds")))
invisible(saveRDS(moran_result, file = moran_path))

```

The Global Moran’s I statistic (I = 0.0435, p \< 0.001) indicates weak but statistically significant positive spatial autocorrelation in hypertension-related CVD mortality at the county level. There is weak-to-moderate positive spatial autocorrelation in mortality rates across U.S. counties — counties with high (or low) mortality tend to be near others with similarly high (or low) values. Although the magnitude is small (I = 0.0435), the pattern is considered statistically significant based on the p-value. This suggests that counties with high mortality rates tend to cluster geographically, rather than being randomly distributed. The presence of spatial autocorrelation supports further analysis using Local Moran’s I to identify specific high- and low-mortality clusters.

After confirming statistically significant spatial autocorrelation at the national level, we use Local Moran’s I to identify potential clusters of high or low mortality at the county level.

###2.4: Local Moran’s I (LISA)

Running Local Moran's I (LISA) to detect local spatial clusters.

```{r lisa-analysis, message=FALSE}

# Run Local Moran’s I (LISA)
local_moran <- localmoran(county_race_sex_sf$mortalities, lw)

# Build a clean spatial object with LISA values
county_lisa <- county_race_sex_sf %>%
  st_drop_geometry() %>%
  bind_cols(geometry = st_geometry(county_race_sex_sf)) %>%
  mutate(local_I = local_moran[, 1],     # Local I statistic
         local_p = local_moran[, 5]) %>% # p-value
  st_as_sf()

# Save outputs
saveRDS(local_moran, file = here::here("results", "output", "local_morans_matrix.rds"))
saveRDS(county_lisa, file = here::here("results", "output", "county_race_sex_sf_with_lisa.rds"))
saveRDS(moran_result, here::here("results", "output", "us_global_morans_i.rds"))

```

Creating map of statistically significant LISA clusters (p \< 0.05).

```{r}

# Create a data frame with centroids for plotting and significance flag
county_lisa_coords <- county_lisa %>%
  mutate(long = st_coordinates(.)[, 1],
    lat = st_coordinates(.)[, 2],
    significant_cluster = ifelse(local_p < 0.05, "p < 0.05", "Not Significant")) %>%
  st_drop_geometry()

# Plot using points instead of polygons
lisa_point_plot <- ggplot(county_lisa_coords) +
  geom_point(aes(x = long, y = lat, color = significant_cluster), alpha = 0.6, size = 0.7) +
  scale_color_manual(values = c("gray80", "red"),
                     labels = c("Not Significant", "p < 0.05")) +
  labs(title = "Counties with Statistically Significant Clustering",
       color = "LISA Significance") +
  coord_equal() +
  theme_minimal(base_size = 12)

# Save plot
invisible(ggsave(filename = here::here("results", "figures", "lisa_significance_map_centroids.png"),
  plot = lisa_point_plot,
  width = 10,
  height = 6))


print(lisa_point_plot)

```

Classifying counties based on LISA cluster type using z-scores.

```{r classify-lisa-clusters, message=FALSE}
# Compute spatial lag of mortality
spatial_lag <- lag.listw(lw, county_lisa$mortalities)

# Standardize original values and spatial lags (z-scores)
mortality_z <- scale(county_lisa$mortalities)[, 1]
lag_z       <- scale(spatial_lag)[, 1]

# Add z-scores and spatial lag to dataset
county_lisa <- county_lisa %>%
  mutate(
    mortality_z = mortality_z,
    lag_z = lag_z,
    lisa_cluster_type = case_when(
      local_p >= 0.05              ~ "Not Significant",
      mortality_z > 0 & lag_z > 0  ~ "High-High",
      mortality_z < 0 & lag_z < 0  ~ "Low-Low",
      mortality_z > 0 & lag_z < 0  ~ "High-Low (Outlier)",
      mortality_z < 0 & lag_z > 0  ~ "Low-High (Outlier)",
      TRUE                         ~ NA_character_))


```

Generating map of LISA cluster types (High-High, Low-Low, Outliers).

```{r lisa-cluster-type-map, message=FALSE}
# Create centroid-based coordinates for plotting
county_lisa_coords <- county_lisa %>%
  mutate(long = st_coordinates(.)[, 1],
         lat = st_coordinates(.)[, 2]) %>%
  st_drop_geometry()

# Define cluster color palette
cluster_colors <- c(
  "High-High" = "red3",
  "Low-Low" = "blue3",
  "High-Low (Outlier)" = "orange",
  "Low-High (Outlier)" = "purple",
  "Not Significant" = "gray85")

# Plot cluster types
lisa_cluster_plot <- ggplot(county_lisa_coords) +
  geom_point(aes(x = long, y = lat, color = lisa_cluster_type), alpha = 0.7, size = 0.75) +
  scale_color_manual(values = cluster_colors) +
  labs(
    title = "Local Spatial Clusters of Mortality (LISA)",
    subtitle = "High–High = Hotspot, Low–Low = Coldspot, Others = Outliers",
    color = "Cluster Type") +
  coord_equal() +
  theme_minimal(base_size = 12)

# Print and save
print(lisa_cluster_plot)

invisible(ggsave(here::here("results", "figures", "lisa_cluster_type_map.png"),
  plot = lisa_cluster_plot,
  width = 10, height = 6))

```

Local Moran’s I was computed on the full national dataset using 5-nearest-neighbor spatial weights. Each county was represented by a centroid, and clustering patterns reflect spatial autocorrelation of mortality rates across all years and subgroups.

#### Focusing at a State level Due to the size of the dataset it is challenging to work with the full dataset.

For convenience and because the SouthEast is historically known to have a high prevalence of cardiovasccular mortalities we will focus on Georgia for this next step. Our previous analysis support that there is a general distribution of cases here, even if there are not distinct hotspots.

Analyzing spatial clusters in Georgia using LISA.

```{r}
# Georgia: Create or load spatial weights
ga_knn_path <- here::here("results", "output", "ga_knn_neighbors.rds")
ga_lw_path  <- here::here("results", "output", "ga_spatial_weights.rds")

county_ga_sf <- county_race_sex_sf %>%
  filter(LocationAbbr == "GA")

if (file.exists(ga_knn_path) && file.exists(ga_lw_path)) {
  message("Reusing saved GA spatial weights and neighbors.")
  ga_knn_nb <- readRDS(ga_knn_path)
  ga_lw <- readRDS(ga_lw_path)
} else {
  message("Generating GA spatial weights.")
  ga_coords <- st_coordinates(county_ga_sf)
  ga_knn_nb <- knn2nb(knearneigh(ga_coords, k = 5))
  ga_lw     <- nb2listw(ga_knn_nb, style = "W")
  saveRDS(ga_knn_nb, file = ga_knn_path)
  saveRDS(ga_lw, file = ga_lw_path)}

```

```{r ga-lisa-analysis, message=FALSE}

# Global Moran's I
ga_moran_result <- moran.test(county_ga_sf$mortalities, ga_lw)
print(ga_moran_result)
saveRDS(ga_moran_result, here::here("results", "output", "ga_global_morans_i.rds"))

# Local Moran's I (LISA)
ga_local_moran <- localmoran(county_ga_sf$mortalities, ga_lw)

# Create cluster type classification
ga_spatial_lag <- lag.listw(ga_lw, county_ga_sf$mortalities)
ga_z <- scale(county_ga_sf$mortalities)[,1]
ga_lag_z <- scale(ga_spatial_lag)[,1]
ga_p <- ga_local_moran[,5]

county_ga_sf <- county_ga_sf %>%
  mutate(
    local_I = ga_local_moran[, 1],
    local_p = ga_p,
    mortality_z = ga_z,
    lag_z = ga_lag_z,
    cluster_type = case_when(
      local_p >= 0.05 ~ "Not Significant",
      mortality_z > 0 & lag_z > 0 ~ "High-High",
      mortality_z < 0 & lag_z < 0 ~ "Low-Low",
      mortality_z > 0 & lag_z < 0 ~ "High-Low (Outlier)",
      mortality_z < 0 & lag_z > 0 ~ "Low-High (Outlier)",
      TRUE ~ NA_character_))

# Plot cluster types using centroids
ga_coords_df <- county_ga_sf %>%
  mutate(long = st_coordinates(.)[,1],
         lat = st_coordinates(.)[,2]) %>%
  st_drop_geometry()

cluster_colors <- c(
  "High-High" = "red3",
  "Low-Low" = "blue3",
  "High-Low (Outlier)" = "orange",
  "Low-High (Outlier)" = "purple",
  "Not Significant" = "gray80")

ga_lisa_plot <- ggplot(ga_coords_df) +
  geom_point(aes(x = long, y = lat, color = cluster_type), alpha = 0.8, size = 2) +
  scale_color_manual(values = cluster_colors) +
  labs(
    title = "LISA Cluster Types: Georgia",
    subtitle = "High–High = Hotspot; Low–Low = Coldspot; Others = Outliers",
    color = "Cluster Type") +
  coord_equal() +
  theme_minimal(base_size = 13)

# Display and save
print(ga_lisa_plot)

invisible(ggsave(here::here("results", "figures", "ga_lisa_cluster_plot.png"),
  plot = ga_lisa_plot,
  width = 8,
  height = 6))
```

A spatial weights matrix was created for Georgia counties using nearest-neighbor distances. LISA statistics were computed to explore clustering, but no statistically significant local hotspots were observed.

Analyzing spatial clusters in Mississippi using LISA.

```{r ms-lisa-analysis, message=FALSE}

# Define file paths for MS spatial objects
ms_knn_path <- here::here("results", "output", "ms_knn_neighbors.rds")
ms_lw_path  <- here::here("results", "output", "ms_spatial_weights.rds")
ms_moran_path <- here::here("results", "output", "ms_global_morans_i.rds")

# Subset to Mississippi (MS)
county_ms_sf <- county_race_sex_sf %>%
  filter(LocationAbbr == "MS")

# Reuse or generate new spatial weights
if (file.exists(ms_knn_path) && file.exists(ms_lw_path)) {
  message("Reusing saved MS spatial weights and neighbors.")
  ms_knn_nb <- readRDS(ms_knn_path)
  ms_lw     <- readRDS(ms_lw_path)
} else {
  message("Generating MS spatial weights.")
  ms_coords <- st_coordinates(county_ms_sf)
  ms_knn_nb <- knn2nb(knearneigh(ms_coords, k = 5))
  ms_lw     <- nb2listw(ms_knn_nb, style = "W")
  
  # Save for reuse
  saveRDS(ms_knn_nb, file = ms_knn_path)
  saveRDS(ms_lw, file = ms_lw_path)}

# Global Moran’s I for MS
ms_moran_result <- moran.test(county_ms_sf$mortalities, ms_lw)
print(ms_moran_result)
saveRDS(ms_moran_result, file = ms_moran_path)

# Local Moran’s I (LISA)
ms_local_moran <- localmoran(county_ms_sf$mortalities, ms_lw)

# Classify cluster types
ms_spatial_lag <- lag.listw(ms_lw, county_ms_sf$mortalities)
ms_z <- scale(county_ms_sf$mortalities)[,1]
ms_lag_z <- scale(ms_spatial_lag)[,1]
ms_p <- ms_local_moran[,5]

county_ms_sf <- county_ms_sf %>%
  mutate(
    local_I = ms_local_moran[, 1],
    local_p = ms_p,
    mortality_z = ms_z,
    lag_z = ms_lag_z,
    cluster_type = case_when(
      local_p >= 0.05 ~ "Not Significant",
      mortality_z > 0 & lag_z > 0 ~ "High-High",
      mortality_z < 0 & lag_z < 0 ~ "Low-Low",
      mortality_z > 0 & lag_z < 0 ~ "High-Low (Outlier)",
      mortality_z < 0 & lag_z > 0 ~ "Low-High (Outlier)",
      TRUE ~ NA_character_))

# Plot with centroids
ms_coords_df <- county_ms_sf %>%
  mutate(long = st_coordinates(.)[,1],
         lat = st_coordinates(.)[,2]) %>%
  st_drop_geometry()

cluster_colors <- c(
  "High-High" = "red3",
  "Low-Low" = "blue3",
  "High-Low (Outlier)" = "orange",
  "Low-High (Outlier)" = "purple",
  "Not Significant" = "gray80")

ms_lisa_plot <- ggplot(ms_coords_df) +
  geom_point(aes(x = long, y = lat, color = cluster_type), alpha = 0.8, size = 2.5) +
  scale_color_manual(values = cluster_colors) +
  labs(
    title = "LISA Cluster Types: Mississippi",
    subtitle = "High–High = Hotspot; Low–Low = Coldspot; Others = Outliers",
    color = "Cluster Type") +
  coord_equal() +
  theme_minimal(base_size = 13)

print(ms_lisa_plot)

invisible(ggsave(filename = here::here("results", "figures", "ms_lisa_cluster_plot.png"),
  plot = ms_lisa_plot,
  width = 8,
  height = 6))

```

LISA analysis for Mississippi counties detected spatial relationships using 5-nearest-neighbor weights. Similar to other states, no prominent local clusters were found despite elevated mortality rates in some areas.

Analyzing spatial clusters in Texas using LISA.

```{r tx-lisa-analysis, message=FALSE}

# Define file paths for Texas-specific spatial objects
tx_knn_path <- here::here("results", "output", "tx_knn_neighbors.rds")
tx_lw_path  <- here::here("results", "output", "tx_spatial_weights.rds")
tx_moran_path <- here::here("results", "output", "tx_global_morans_i.rds")

# Subset to Texas counties
county_tx_sf <- county_race_sex_sf %>%
  filter(LocationAbbr == "TX")

# Reuse or generate neighbors/weights
if (file.exists(tx_knn_path) && file.exists(tx_lw_path)) {
  message("Reusing saved TX spatial weights and neighbors.")
  tx_knn_nb <- readRDS(tx_knn_path)
  tx_lw     <- readRDS(tx_lw_path)
} else {
  message("Generating TX spatial weights.")
  tx_coords <- st_coordinates(county_tx_sf)
  tx_knn_nb <- knn2nb(knearneigh(tx_coords, k = 5))
  tx_lw     <- nb2listw(tx_knn_nb, style = "W")
  
  # Save for reuse
  saveRDS(tx_knn_nb, file = tx_knn_path)
  saveRDS(tx_lw, file = tx_lw_path)
}

```

```{r tx-lisa-analysis, message=FALSE}

# Global Moran’s I for Texas
tx_moran_result <- moran.test(county_tx_sf$mortalities, tx_lw)
print(tx_moran_result)
saveRDS(tx_moran_result, file = tx_moran_path)

# Local Moran’s I (LISA)
tx_local_moran <- localmoran(county_tx_sf$mortalities, tx_lw)

# Spatial lag and z-scores
tx_spatial_lag <- lag.listw(tx_lw, county_tx_sf$mortalities)
tx_z <- scale(county_tx_sf$mortalities)[,1]
tx_lag_z <- scale(tx_spatial_lag)[,1]
tx_p <- tx_local_moran[,5]

# Add LISA values and classification
county_tx_sf <- county_tx_sf %>%
  mutate(
    local_I = tx_local_moran[, 1],
    local_p = tx_p,
    mortality_z = tx_z,
    lag_z = tx_lag_z,
    cluster_type = case_when(
      local_p >= 0.05 ~ "Not Significant",
      mortality_z > 0 & lag_z > 0 ~ "High-High",
      mortality_z < 0 & lag_z < 0 ~ "Low-Low",
      mortality_z > 0 & lag_z < 0 ~ "High-Low (Outlier)",
      mortality_z < 0 & lag_z > 0 ~ "Low-High (Outlier)",
      TRUE ~ NA_character_))

# Convert to points (centroids) for visualization
tx_coords_df <- county_tx_sf %>%
  mutate(long = st_coordinates(.)[,1],
         lat = st_coordinates(.)[,2]) %>%
  st_drop_geometry()

# Cluster colors
cluster_colors <- c(
  "High-High" = "red3",
  "Low-Low" = "blue3",
  "High-Low (Outlier)" = "orange",
  "Low-High (Outlier)" = "purple",
  "Not Significant" = "gray80")

# Plot
tx_lisa_plot <- ggplot(tx_coords_df) +
  geom_point(aes(x = long, y = lat, color = cluster_type), alpha = 0.8, size = 2) +
  scale_color_manual(values = cluster_colors) +
  labs(
    title = "LISA Cluster Types: Texas",
    subtitle = "High–High = Hotspot; Low–Low = Coldspot; Others = Outliers",
    color = "Cluster Type") +
  coord_equal() +
  theme_minimal(base_size = 13)

print(tx_lisa_plot)

# Save plot
invisible(ggsave(filename = here::here("results", "figures", "tx_lisa_cluster_plot.png"),
  plot = tx_lisa_plot,
  width = 9, height = 6))
```

LISA analysis was performed on counties in Texas using centroid-based spatial weights. While global spatial autocorrelation was detected, no statistically significant local clusters were identified.

Analyzing spatial clusters in Kentucky using LISA.

```{r}
# Paths for saving spatial weights
ky_knn_path <- here::here("results", "output", "ky_knn_neighbors.rds")
ky_lw_path  <- here::here("results", "output", "ky_spatial_weights.rds")

# Subset to Kentucky counties
county_ky_sf <- county_race_sex_sf %>%
  filter(LocationAbbr == "KY")

# Reuse or generate spatial weights for Kentucky
if (file.exists(ky_knn_path) && file.exists(ky_lw_path)) {
  message("Reusing saved KY spatial weights and neighbors.")
  ky_knn_nb <- readRDS(ky_knn_path)
  ky_lw     <- readRDS(ky_lw_path)
} else {
  message("Generating KY spatial weights.")
  ky_coords <- st_coordinates(county_ky_sf)
  ky_knn_nb <- knn2nb(knearneigh(ky_coords, k = 5))
  ky_lw     <- nb2listw(ky_knn_nb, style = "W")

  # Save for reuse
  saveRDS(ky_knn_nb, file = ky_knn_path)
  saveRDS(ky_lw, file = ky_lw_path)
}

# Compute local Moran’s I
local_moran_ky <- localmoran(county_ky_sf$mortalities, ky_lw)

# Add results to object
county_ky_sf <- county_ky_sf %>%
  mutate(
    local_I = local_moran_ky[, 1],
    local_p = local_moran_ky[, 5],
    mortality_z = scale(mortalities)[, 1],
    lag_z = lag.listw(ky_lw, mortality_z),
    lisa_cluster = case_when(
      local_p > 0.05 ~ "Not Significant",
      mortality_z > 0 & lag_z > 0 ~ "High-High",
      mortality_z < 0 & lag_z < 0 ~ "Low-Low",
      mortality_z > 0 & lag_z < 0 ~ "High-Low (Outlier)",
      mortality_z < 0 & lag_z > 0 ~ "Low-High (Outlier)",
      TRUE ~ NA_character_))

# Get centroid coordinates
county_ky_coords <- county_ky_sf %>%
  mutate(long = st_coordinates(.)[, 1],
         lat = st_coordinates(.)[, 2]) %>%
  st_drop_geometry()

# Plot
lisa_ky_plot <- ggplot(county_ky_coords) +
  geom_point(aes(x = long, y = lat, color = lisa_cluster), alpha = 0.7, size = 0.8) +
  scale_color_manual(
    values = c("High-High" = "red", "Low-Low" = "blue",
               "High-Low (Outlier)" = "orange", "Low-High (Outlier)" = "purple", "Not Significant" = "gray80"),
    na.value = "black"
  ) +
  labs(
    title = "LISA Cluster Types: Kentucky",
    subtitle = "High–High = Hotspot; Low–Low = Coldspot; Others = Outliers",
    color = "Cluster Type"
  ) +
  coord_equal() +
  theme_minimal(base_size = 12)

# Save
invisible(ggsave(here::here("results", "figures", "lisa_cluster_kentucky.png"),
  plot = lisa_ky_plot, width = 9, height = 6))


# Compute Global Moran’s I for Kentucky
ky_moran_result <- moran.test(county_ky_sf$mortalities, ky_lw)

# Save the result
invisible(saveRDS(ky_moran_result, here::here("results", "output", "ky_global_morans_i.rds")))

print(lisa_ky_plot)

```

the LISA plot shows spatial patterns across all available data, not just one year

The Local Moran’s I analysis detected significant spatial clustering of mortality rates across U.S. counties. Nationally, over 40% of counties showed statistically significant clustering at p \< 0.05. However, most of these represented spatial outliers—counties with high (or low) mortality rates surrounded by contrasting neighbors—rather than concentrated hotspots. Only a small number of “High–High” clusters (hotspots) were identified, indicating that extreme spatial concentrations of high mortality are rare.

Cluster types varied across states:

In Georgia, clustering was driven primarily by High–Low outliers and a few Low–Low coldspots, especially in the northern region.

Mississippi showed a similar pattern, with isolated High–Low counties in the central and southern parts of the state.

In Texas, counties in the western and southern regions showed a mix of Low–Low coldspots and High–Low outliers, with no evidence of strong regional hotspots.

Kentucky had a slightly denser distribution of significant clusters, including more scattered High–Low and Low–Low counties. A few High–High hotspots were detected but did not form a continuous cluster.

Local spatial analysis (LISA) identified a small number of statistically significant clusters in Kentucky, including high-mortality counties adjacent to other high-mortality areas. These patterns support the presence of localized mortality hotspots.

Across all states, the most consistent pattern was the presence of outlier counties—areas with mortality rates that diverged significantly from their neighbors.

Compile Global Moran’s I test results from the USA and selected high-mortality states (GA, MS, TX, KY). This table summarizes the spatial autocorrelation of mortality rates.

### 2.5 Global Moran's I Summary Table

```{r}
# Already saved or placed earlier
extract_moran_values <- function(obj, geo) {
  tibble(
    Geography = geo,
    `Moran's I` = round(obj$estimate[["Moran I statistic"]], 4),
    Expectation = round(obj$estimate[["Expectation"]], 4),
    Variance = round(obj$estimate[["Variance"]], 6),
    `Z Statistic` = round(obj$statistic, 4),
    `p-value` = signif(obj$p.value, 4))}

# Load all Moran's I results
usa_moran <- readRDS(here::here("results", "output", "global_morans_i.rds"))
ga_moran  <- readRDS(here::here("results", "output", "ga_global_morans_i.rds"))
ms_moran  <- readRDS(here::here("results", "output", "ms_global_morans_i.rds"))
tx_moran  <- readRDS(here::here("results", "output", "tx_global_morans_i.rds"))
ky_moran  <- readRDS(here::here("results", "output", "ky_global_morans_i.rds"))

# Build summary table
moran_summary <- bind_rows(
  extract_moran_values(usa_moran, "USA (All Counties)"),
  extract_moran_values(ga_moran,  "Georgia"),
  extract_moran_values(ms_moran,  "Mississippi"),
  extract_moran_values(tx_moran,  "Texas"),
  extract_moran_values(ky_moran,  "Kentucky"))

# Format with gt
moran_gt_tbl <- moran_summary %>%
  gt() %>%
  tab_header(
    title = "Global Moran's I Statistics by Geography",
    subtitle = "Spatial Autocorrelation of Mortality Rates"
  ) %>%
  fmt_number(columns = 2:5, decimals = 4) %>%  # Keep decimals for other metrics
  fmt_scientific(columns = vars(`p-value`), decimals = 2) %>%  # Use sci notation for p-values
  cols_label(
    `Moran's I` = "Moran's I",
    `Z Statistic` = "Z Statistic",
    `p-value` = "p-value"
  ) %>%
  tab_options(
    table.font.size = px(12),
    heading.title.font.size = px(14),
    heading.subtitle.font.size = px(12),
    column_labels.font.weight = "bold")

# Save table
invisible(saveRDS(moran_gt_tbl, here::here("results", "tables", "moran_global_summary.rds")))

# View
moran_gt_tbl
```

A summary table of Global Moran’s I statistics for the full U.S. dataset and selected states (GA, MS, TX, KY) is shown below, indicating statistically significant spatial autocorrelation in all geographies examined (p \< 0.001).

Global Moran’s I statistics were statistically significant across all regions analyzed. The USA showed weak but significant positive spatial autocorrelation (I = 0.0435, p \< 0.001). Georgia, Mississippi, Texas, and Kentucky also had low Moran’s I values (0.0168–0.0297), but all were statistically significant (p \< 0.001), confirming that mortality rates were not randomly distributed in space. These findings support further investigation of local spatial clustering using LISA.

## Aim 3: Demographic Disparities

### 3.1: Estimated sloped by Race and Sex

Slope Comparison by Race and Sex using emmeans function for all ages.

Extract estimated annual mortality trends by race/ethnicity and sex across all adults (35+). These values represent the modeled rate of change in mortality per year.

```{r}
# Extract estimated yearly trends (slopes) by race_ethnicity and sex
em_trends_race_sex <- emtrends(glm_model_interaction, ~ race_ethnicity + sex, var = "Year")

# Summarize estimated slopes
# View slope estimates (with SE and CI) for each group
summary(em_trends_race_sex)
print(em_trends_race_sex)

# Extract model fit metrics
model_fit_race_sex <- broom::glance(glm_model_interaction) %>%
  dplyr::mutate(model = "GLM: Race × Sex × Year")

# Save for results
invisible(saveRDS(model_fit_race_sex, here::here("results", "tables", "model_fit_race_sex.rds")))

# Create a table of slopes for each race-sex group 
# Format slope estimates for manuscript table
slope_table_race_sex_fmt <- as.data.frame(summary(em_trends_race_sex)) %>%
  dplyr::mutate(
    Estimate = round(Year.trend, 3),
    CI = paste0(round(lower.CL, 2), "–", round(upper.CL, 2)),
    SE = round(SE, 3)) %>%
  dplyr::select(Race = race_ethnicity, Sex = sex, Estimate, SE, CI)

# Save nicely formatted table
invisible(saveRDS(slope_table_race_sex_fmt, here::here("results", "tables", "slope_table_race_sex_fmt.rds")))

#Display table:
#Note: p.value of 0.00e+00 is actually p < 2.2e-16
view(slope_table_race_sex_fmt)


# Create high-quality PNG table for manuscript
slope_table_race_sex_gt <- slope_table_race_sex_fmt %>%
  gt() %>%
  tab_header(
    title = "Estimated Annual Mortality Slopes by Race/Ethnicity and Sex",
    subtitle = "From GLM with Year × Race × Sex Interaction"
  ) %>%
  fmt_number(columns = c(Estimate, SE), decimals = 3) %>%
  cols_label(
    Race = "Race/Ethnicity",
    Sex = "Sex",
    Estimate = "Slope",
    SE = "Standard Error",
    CI = "95% CI"
  ) %>%
  opt_table_font(font = google_font("Roboto")) %>%
  tab_options(table.font.size = 10)

# Save as image for manuscript inclusion
gtsave(
  slope_table_race_sex_gt,
  filename = here::here("results", "tables", "slope_table_race_sex.png")
)

slope_table_race_sex_gt

```

```{r}
# Compare slopes between race/sex groups
slope_contrast_race_sex <- contrast(em_trends_race_sex, method = "pairwise")

# View significance of differences in slopes
summary(slope_contrast_race_sex)
print(slope_contrast_race_sex)

# Save slope estimates and pairwise contrasts
invisible(saveRDS(em_trends_race_sex, file = here::here("results", "output", "emtrends_race_sex.rds")))
invisible(saveRDS(slope_contrast_race_sex, file = here::here("results", "output", "slope_contrast_race_sex.rds")))

# Create a table comparing slopewise pairwise comparison between groups for each race-sex group
# Format race/sex slope difference table
slope_contrast_race_sex_fmt <- as.data.frame(summary(slope_contrast_race_sex, infer = c(TRUE, TRUE))) %>%
  dplyr::mutate(
    Estimate = round(estimate, 3),
    CI = paste0(round(lower.CL, 2), "–", round(upper.CL, 2)),
    SE = round(SE, 3),
    p_value = signif(p.value, 3)) %>%
  dplyr::select(Contrast = contrast, Estimate, SE, CI, p_value)

#Sort table results by significance (p-value)
slope_contrast_race_sex_fmt_sorted <- slope_contrast_race_sex_fmt %>%
  arrange(p_value, desc(abs(Estimate)))


# Save to results folder
saveRDS(slope_contrast_race_sex_fmt, here::here("results", "output", "slope_contrast_race_sex_fmt.rds"))
saveRDS(slope_contrast_race_sex_fmt_sorted,here::here("results", "output", "slope_contrast_race_sex_sorted.rds"))

# view results from the sorted table 
slope_contrast_race_sex_fmt_sorted

# Plot slope estimates
slope_plot_race_sex <- plot(em_trends_race_sex) +
  ggtitle("Estimated Annual Mortality Change by Race and Sex") +
  ylab("Yearly Slope Estimate") +
  xlab("Race and Sex Group") +
  theme_minimal(base_size = 12)


# Save and display the plot
invisible(ggsave(here::here("results", "figures", "slope_plot_race_sex.png"),
       plot = slope_plot_race_sex, width = 10, height = 6))
print(slope_plot_race_sex)
```

Estimated yearly mortality rate trends were computed for each race and sex group. Positive slope estimates indicate increasing mortality over time, while negative values suggest improvements. Pairwise comparisons were used to assess whether these differences were statistically significant across groups. This was for all ages aged 35+ (both groups combined).

-   Black adults, particularly Black females, showed the steepest and most consistently negative slopes (−3.69 deaths per 100,000 per year, 95% CI: −4.07 to −3.30), indicating large annual declines in mortality. These trends were significantly different from nearly all other groups, with pairwise differences of over 7 points when compared to American Indian and Alaska Native (AIAN) individuals, and around 5.7 points compared to White adults (p \< 2.2e-16).
-   In contrast, American Indian and Alaska Native adults had the most positive slopes (\~+3.38 per year), suggesting a consistent increase in hypertension-related CVD mortality over time. These trends were significantly higher than all other groups, especially when compared to Black, Hispanic, and Asian and Pacific Islander subgroups.
-   White adults had moderately positive slope estimates (\~+1.98 per year), significantly higher than those for Asian, Black, and Hispanic adults. -Hispanic adults and Asian and Pacific Islander adults showed relatively flat to slightly negative trends. These groups had annual change estimates that were not significantly different from zero, with confidence intervals crossing or approaching zero. Differences from the “Overall” group estimates were also generally not statistically significant.
-   Several race/sex combinations (e.g., Black Female vs. White Male; AIAN Male vs. Hispanic Male) yielded statistically significant contrasts, with p \< 2e-16 for many pairwise comparisons, further reinforcing the existence of sharp disparities in trend slopes. These findings suggest that while national mortality may be decreasing on average, substantial heterogeneity by race and sex persists. The increasing trends in mortality among AIAN individuals are particularly concerning, in contrast to strong improvements among Black adults.

While the above results illustrate broad disparities across race and sex, they do not account for variation by age. We next fit an age-adjusted model to stratify mortality trends by age group and explore how disparities unfold differently for younger and older adults.

### 3.2 Demogrpahic disparities by Age group

We now wish to use a model to extract yearly mortality trends by combinations of race/ethnicity and sex while adjusting for age group to see the impact of demosgraphic disparities between age groups. To assess disparities across age, we fit a GLM including three-way interactions between year, race/ethnicity, and sex, adjusting for age group. This allows age-stratified analysis of temporal trends.

Fit the Interaction Model

```{r}
# GLM with 3-way interaction to explore mortality trends by Year * race_ethnicity * sex, stratified by age group

## ---- load_glm_race_sex_age_model, message=TRUE, warning=FALSE -------------------

glm_path <- here::here("results", "output", "glm_race_sex_age_model.rds")

if (file.exists(glm_path)) {
  message("Loading saved GLM model with 3-way interaction...")
  glm_race_sex_age <- readRDS(glm_path)
} else {
  message("Fitting GLM model with 3-way interaction...")
  glm_race_sex_age <- glm(mortalities ~ Year * race_ethnicity * sex + age_group,
                          data = county_race_sex, family = gaussian())
  saveRDS(glm_race_sex_age, glm_path)}


#glm_race_sex_age <- glm(mortalities ~ Year * race_ethnicity * sex + age_group, data = processed_data_no_percent, family = gaussian())

# Save model
#saveRDS(glm_race_sex_age, here::here("results", "output", "glm_race_sex_age_model.rds"))


```

We fit a GLM with 3-way interactions between year, race/ethnicity, and sex, while adjusting for age group. This allows us to examine mortality trends by race and sex, separately for younger and older adults.

Get Estimated Slopes Stratified by Age Group

```{r}
# Extract yearly slopes within each race-sex group, stratified by age_group
em_trends_race_sex_age <- emtrends(glm_race_sex_age,
                                   ~ race_ethnicity + sex | age_group,
                                   var = "Year")

# Save slopes
invisible(saveRDS(em_trends_race_sex_age, here::here("results", "output", "emtrends_race_sex_by_age.rds")))

# Print to console
summary(em_trends_race_sex)
```

This extracts slope estimates (rate of annual change in mortality) for each demographic subgroup, separately for younger and older adults. Estimated yearly changes in mortality rates were extracted for each race/sex group, stratified by age. This approach highlights disparities not only across race and sex but also how these trends differ across age strata.

Estimated annual mortality trends stratified by race/ethnicity and sex (adjusted for age group) revealed substantial variation. Black males and females had the steepest declines in mortality, with yearly slopes of –3.685 deaths per 100,000 (SE = 0.197). In contrast, American Indian and Alaska Native males and females showed the largest increases, with an estimated yearly change of +3.380 (SE = 0.471). White males and females experienced increasing trends (Estimate = +1.983, SE = 0.116), while mortality trends for Hispanic adults were nearly flat (Estimate = –0.030, SE = 0.259). Asian and Pacific Islander adults showed modest decreases (Estimate = –0.918, SE = 0.361).

### 3.3 Pairwise Comparisons Within Each Age Group

Compare estimated slopes between all demographic subgroups within each age group using pairwise contrasts.

```{r}
# Compare slopes between race/sex groups within each age group
slope_contrast_race_sex_age <- contrast(em_trends_race_sex_age, method = "pairwise")

# Save
invisible(saveRDS(slope_contrast_race_sex_age, here::here("results", "output", "slope_contrast_race_sex_by_age.rds")))

# Convert to dataframe
slope_contrast_race_sex_age_fmt <- as.data.frame(summary(slope_contrast_race_sex_age, infer = c(TRUE, TRUE))) %>%
  dplyr::mutate(
    Estimate = round(estimate, 3),
    SE = round(SE, 3),
    CI = paste0(round(lower.CL, 2), "–", round(upper.CL, 2)),
    p_value = signif(p.value, 3)) %>%
  dplyr::select(age_group, Contrast = contrast, Estimate, SE, CI, p_value)

# Sort by p-value and effect size 
slope_contrast_race_sex_age_sorted <- slope_contrast_race_sex_age_fmt %>%
  dplyr::arrange(p_value, dplyr::desc(abs(Estimate)))

# Save output
invisible(saveRDS(slope_contrast_race_sex_age_sorted, here::here("results", "output", "slope_contrast_race_sex_by_age_sorted.rds")))

# View sorted results
view(slope_contrast_race_sex_age_sorted)

```

Pairwise comparisons were conducted to formally test differences in temporal mortality trends between groups within each age group. These contrasts help assess whether slope differences between groups are statistically significant within each age group.

The pairwise comparisons of estimated yearly trends within each age group revealed highly consistent results across both age strata (35–64 and 65+). Black adults had the steepest declines in hypertension-related CVD mortality, significantly differing from all other race-sex groups (e.g., Black vs. Overall Male: −7.00 per year, SE = 0.12, p \< 2.2e-16). In contrast, American Indian and Alaska Native adults consistently showed the most rapid increases in mortality rates (e.g., AI/AN vs. Black Overall: +6.95 per year, SE = 0.36, p \< 2.2e-16). Differences between sexes within race/ethnicity were not estimable in this output, with many comparisons yielding NA. These results reinforce the magnitude and consistency of racial disparities seen in the earlier pooled model.

###3.4: Visualize Slope Contrasts Top slope differences (absolute magnitude) were visualized to highlight which subgroup comparisons showed the greatest disparities. Significant differences (p \< 0.05) are shown in red.

```{r}
# Summarize the contrast object
contrast_summary <- as.data.frame(summary(slope_contrast_race_sex_age, infer = c(TRUE, TRUE))) %>%
  filter(!is.na(estimate)) %>%  # remove any NAs if they exist
  mutate(
    significant = p.value < 0.05,
    contrast = factor(contrast))

contrast_top <- contrast_summary %>%
  arrange(desc(abs(estimate))) %>%
  group_by(age_group) %>%
  slice_head(n = 20) %>%   # Top 20 slope differences per age group
  ungroup()

# Plot
contrast_plot <- ggplot(contrast_top, aes(x = estimate, y = reorder(contrast, estimate), color = significant)) +
  geom_point(size = 2) +
  geom_errorbarh(aes(xmin = estimate - 1.96 * SE, xmax = estimate + 1.96 * SE), height = 0.3) +
  facet_wrap(~ age_group, scales = "free_y") +
  scale_color_manual(values = c("TRUE" = "red", "FALSE" = "gray40")) +
  labs(
    title = "Top Pairwise Differences in Annual Mortality Trends by Race and Sex",
    x = "Estimated Difference in Yearly Mortality Slope",
    y = "Group Comparison",
    color = "Significant (p < 0.05)") +
  theme_minimal(base_size = 11)

# Save and display
invisible(ggsave(here::here("results", "figures", "pairwise_slope_contrasts_filtered.png"),
  plot = contrast_plot, width = 11, height = 8))
print(contrast_plot)

```

To improve clarity, cleaned labels were applied to simplify group names and facet plots were split by age group. Bar height reflects annual change in mortality; error bars represent 95% confidence intervals.

```{r}
# Helper function to clean group labels (removes age group text)
clean_labels <- function(df) {
  df %>%
    mutate(
      group = str_remove(group, "___Ages 35-64 years"),
      group = str_remove(group, "___Ages 65\\+ years"),
      group = str_replace_all(group, "Asian and Pacific Islander", "Asian & Pacific Islander"),
      group = str_replace_all(group, "American Indian and Alaska Native", "American Indian & Alaska Native"),
      group = case_when(
        str_detect(group, "^Overall Female") ~ "Overall Female (All Races)",
        str_detect(group, "^Overall Male") ~ "Overall Male (All Races)",
        str_detect(group, "^Overall Overall") ~ "Overall (All Races and Sexes)",
        TRUE ~ group
      ),
      group = str_squish(group),
      group = str_wrap(group, width = 18))}

# Convert estimated emtrends object to a data frame for plotting
# Create a group label that includes race, sex, and age group
# Apply and split
slope_df <- as.data.frame(em_trends_race_sex_age) %>%
  mutate(group = paste(race_ethnicity, sex),
         group = paste(group, age_group, sep = "___"))

slope_df_35_64 <- slope_df %>% filter(age_group == "Ages 35-64 years") %>% clean_labels()
slope_df_65_plus <- slope_df %>% filter(age_group == "Ages 65+ years") %>% clean_labels()

# Final slope plot function
make_slope_plot <- function(data, title_text, fill_color) {
  data %>%
    filter(!is.na(group), !is.na(Year.trend)) %>%
    mutate(group = fct_reorder(group, Year.trend)) %>%
    ggplot(aes(x = Year.trend, y = group)) +
    geom_col(fill = fill_color, width = 0.7, alpha = 0.9) +
    geom_errorbarh(
      aes(xmin = Year.trend - 1.96 * SE, xmax = Year.trend + 1.96 * SE),
      height = 0.3, color = "black", alpha = 0.7
    ) +
    labs(
      title = title_text,
      subtitle = "Estimated slope with 95% CI from GLM (Year × Race × Sex)",
      x = "Estimated Annual Change in Mortality Rate (per 100,000)",
      y = "Race/Sex Group"
    ) +
    theme_minimal(base_size = 14) +
    theme(
      plot.title = element_text(size = 18, face = "bold", hjust = 0.5),
      plot.subtitle = element_text(size = 16, hjust = 0.5),
      axis.title = element_text(size = 15),
      axis.text.y = element_text(size = 15),
      axis.text.x = element_text(size = 15)
    )
}

# Create final plots
slope_plot_35_64 <- make_slope_plot(slope_df_35_64, "Estimated Annual Mortality Change (Ages 35–64)", "#4C78A8")
slope_plot_65_plus <- make_slope_plot(slope_df_65_plus, "Estimated Annual Mortality Change (Ages 65+)", "#A2C7E5")

# Save both
ggsave(here("results", "figures", "slope_plot_35_64.png"), slope_plot_35_64, width = 10.5, height = 7, dpi = 300)
ggsave(here("results", "figures", "slope_plot_65_plus.png"), slope_plot_65_plus, width = 10.5, height = 7, dpi = 300)

#Save slimmed RDS for manuscript or reuse
saveRDS(slope_plot_35_64, here("results", "output", "statistical-analysis", "slope_plot_35_64.rds"))
saveRDS(slope_plot_65_plus, here("results", "output", "statistical-analysis", "slope_plot_65_plus.rds"))

slope_plot_35_64
slope_plot_65_plus 

```

Estimated annual change in hypertension-related CVD mortality per 100,000 adults, stratified by race/ethnicity and age group (2000–2019). Bars represent modeled slope estimates, and error bars represent 95% confidence intervals. “Overall” groups include both sexes; sex-specific estimates were excluded where modeling was not feasible.

To complement the full slope estimates by group (3.2), we visualized the top pairwise contrasts from 3.3 by effect size and statistical significance. The plot highlights that the largest and most statistically significant differences in annual mortality trends consistently involved comparisons with Black adults, particularly between Black individuals and males or American Indian/Alaska Native groups. These patterns were consistent across both age groups. Many subgroup comparisons were statistically significant (red), with several slope differences exceeding ±4 deaths per 100,000 annually.

We assessed yearly changes in hypertension-related cardiovascular disease (CVD) mortality across race/ethnicity and sex groups, stratified by age (35–64 and 65+ years). Modeled slope estimates revealed significant disparities in temporal mortality trends. Black individuals consistently showed the largest reductions in mortality over time, while males and American Indian/Alaska Native populations experienced the steepest increases. These patterns were consistent across both age groups. Pairwise comparisons highlighted statistically significant differences between subgroups, especially between Black adults and other demographic groups. Overall, these findings indicate that improvements in CVD mortality have not been shared equally across populations and age groups.

Overview of the Summary Statistics before modeling.

### Descriptive Statistics of County-Level Mortality Rates by Demographics

To contextualize the above modeling results, we summarize baseline mortality distributions across race/sex/age combinations.

```{r}
# Summary by race, sex, and age group
mortality_summary_table <- county_race_sex %>%
  drop_na(mortalities, race_ethnicity, sex, age_group) %>%
  group_by(race_ethnicity, sex, age_group) %>%
  summarise(
    n = n(),
    mean_mortality = round(mean(mortalities, na.rm = TRUE), 2),
    sd = round(sd(mortalities, na.rm = TRUE), 2),
    min = round(min(mortalities, na.rm = TRUE), 2),
    max = round(max(mortalities, na.rm = TRUE), 2),
    .groups = "drop"
  )

# Save for manuscript
invisible(saveRDS(mortality_summary_table, here::here("results", "tables", "mortality_summary_table.rds")))

mortality_summary_table
```

We provide baseline descriptive statistics of hypertension-related CVD mortality to contextualize the modeled slope differences. Among adults aged 35–64, Black individuals had the highest mean mortality rate (92.2 per 100,000), followed by American Indian and Alaska Native (AI/AN) adults (46.2), with Asian and Pacific Islander adults showing the lowest (17.7). These patterns were consistent in the 65+ age group, where Black adults again had the highest average mortality (662.6), while Asian and Pacific Islander adults had the lowest (308.7). The wide ranges and standard deviations suggest substantial geographic heterogeneity, particularly in older adults. These differences reinforce the need for stratified modeling.

## Aim 4: Predict County-level Mortality rates

In this section, we evaluate predictive models for estimating county-level hypertension-related cardiovascular disease (CVD) mortality based on demographic and temporal predictors, including race/ethnicity, sex, age group, and year.

### 4.1 Data Preparation for modeling

We begin by loading the cleaned dataset, removing missing values, and splitting the data into training and testing sets stratified by mortality outcomes.

```{r}
# Set seed for reproducibility
set.seed(123)

# Use the cleaned modeling dataset
model_data <- county_race_sex %>%
  drop_na(mortalities, Year, age_group, race_ethnicity, sex)  # Remove rows with missing key variables

# Initial train/test split (80/20) - test split stratified by outcome
data_split <- initial_split(model_data, prop = 0.8, strata = mortalities)
train_data <- training(data_split)
test_data  <- testing(data_split)

# 10-fold cross-validation folds (stratified by outcome)
cv_folds <- vfold_cv(train_data, v = 10, strata = mortalities)

```

## 4.2 Random Forest Modeling

We first fit a Random Forest model, tuning hyperparameters with cross-validation and evaluating performance on the held-out test set.

Generating the processing recipe and model workflow

```{r}
# Preprocessing recipe
mortality_recipe <- recipe(mortalities ~ Year + age_group + race_ethnicity + sex, data = train_data) %>%
  step_dummy(all_nominal_predictors()) %>%  # Convert categorical predictors to dummies
  step_zv(all_predictors()) %>%             # Remove zero-variance predictors (if any)
  step_normalize(all_numeric_predictors())  # Normalize numeric predictors (being cautious)

# Define random forest model
rf_model <- rand_forest(
  mtry = tune(),     # number of variables to try at each split 
  trees = 500,       # total number of trees
  min_n = tune()     # minimum data points in a node 
) %>%
  set_engine("ranger", importance = "impurity") %>%  # impurity-based variable importance
  set_mode("regression")

# Combine into a workflow
rf_workflow <- workflow() %>%
  add_model(rf_model) %>%
  add_recipe(mortality_recipe)

```

Hyperparamter tuning and fitting a random forest model: We will tune a random forest with 10-Fold cross-validation:

### 4.2.1 Hyperparameter Tuning

To optimize the number of predictors (`mtry`) and minimum node size (`min_n`), we perform 10-fold cross-validation over a regular grid of parameter values. \# Define path to save tuning results

Creeating a slimmed down version of the tuning RDS file to reduce file size for Github and working with if statements to load this from the correct folder and to not overwrite files.

```{r}
## ---- rf_tune_and_fit_if_guarded, message=TRUE, warning=FALSE -------------------

# Create directories
dir.create(here("results", "output"), recursive = TRUE, showWarnings = FALSE)
dir.create(here("results", "large-files"), recursive = TRUE, showWarnings = FALSE)

# Define output paths
rf_tuned_path     <- here("results", "large-files", "rf_tuned.rds")
rf_metrics_path   <- here("results", "output", "rf_tuned_metrics.rds")
rf_best_param_path <- here("results", "output", "rf_best_params.rds")
rf_grid_path      <- here("results", "output", "rf_grid.rds")
rf_slim_path      <- here("results", "output", "rf_model_minimal.rds")

# Check if all exist
if (file.exists(rf_tuned_path) && file.exists(rf_metrics_path) &&
    file.exists(rf_best_param_path) && file.exists(rf_slim_path)) {

  message(" All RF files found. Loading saved versions...")

  rf_tuned <- readRDS(rf_tuned_path)
  rf_metrics <- readRDS(rf_metrics_path)
  best_rf_params <- readRDS(rf_best_param_path)
  rf_slim <- readRDS(rf_slim_path)
  rf_final_model <- rf_slim$model
  rf_vip <- rf_slim$vip

} else {
  message("Fitting Random Forest from scratch...")

  # Define grid
  rf_grid <- grid_regular(
    mtry(range = c(1, 4)),
    min_n(range = c(5, 25)),
    levels = 3)
  saveRDS(rf_grid, rf_grid_path)

  # Tune
  set.seed(123)
  rf_tuned <- tune_grid(
    rf_workflow,
    resamples = cv_folds,
    grid = rf_grid,
    metrics = metric_set(rmse, rsq, mae),
    control = control_grid(save_pred = TRUE))

  # Extract results
  rf_metrics <- collect_metrics(rf_tuned)
  best_rf_params <- select_best(rf_tuned, metric = "rmse")

  # Save tuning results
  saveRDS(rf_tuned, rf_tuned_path)
  saveRDS(rf_metrics, rf_metrics_path)
  saveRDS(best_rf_params, rf_best_param_path)

  # Finalize and fit full model
  final_rf_workflow <- finalize_workflow(rf_workflow, best_rf_params)

  set.seed(123)
  rf_final_model <- fit(final_rf_workflow, data = train_data)

  # VIP
  rf_vip <- extract_fit_parsnip(rf_final_model) %>% vip::vi()

  # Save slim model
  saveRDS(
    list(model = rf_final_model, metrics = rf_metrics, vip = rf_vip),
    file = rf_slim_path)

  message("RF slim model and all outputs saved.")}

```

The slim model can be toggled on or off here by changing from TRUE to FALSE if wanting to use the full version. The full RDS file is saved in the large-files folder which will not automatically upload to github.

```{r}
#Slim version already loads rf_metrics, so no need to reload
rf_metrics %>% filter(.metric == "rmse") %>% arrange(mean)

```

The optimal Random Forest model was selected with mtry = 4 and min_n = 15, yielding the lowest cross-validated RMSE (115.2). Performance differences between parameter combinations were minor when mtry = 4, but models with fewer predictors showed substantially higher RMSE values.

```{r}
# Build summary with 95% CI
rf_cv_summary <- rf_metrics %>%
  filter(.metric %in% c("rmse", "rsq")) %>%
  mutate(
    lower_95 = mean - 1.96 * std_err,
    upper_95 = mean + 1.96 * std_err,
    ci_range = paste0(sprintf("%.2f", mean), " [", 
                      sprintf("%.2f", lower_95), ", ", 
                      sprintf("%.2f", upper_95), "]")
  ) %>%
  select(.metric, ci_range, mtry, min_n) %>%
  arrange(.metric, mtry)

# Get row with best RMSE
rf_cv_summary_table <- rf_cv_summary %>%
  group_by(.metric) %>%
  slice_min(mtry, n = 1) %>%
  ungroup() %>%
  tidyr::pivot_wider(names_from = .metric, values_from = ci_range) %>%
  rename(
    `mtry` = mtry,
    `min_n` = min_n,
    `RMSE (95% CI)` = rmse,
    `R² (95% CI)` = rsq
  )

# Create GT table
rf_cv_gt <- rf_cv_summary_table %>%
  gt() %>%
  tab_header(
    title = md("**Random Forest CV Performance Summary**"),
    subtitle = "Mean performance across 10-fold CV with 95% confidence intervals"
  ) %>%
  tab_options(
    table.font.size = "small",
    table.width = pct(70),
    column_labels.font.weight = "bold",
    data_row.padding = px(3)
  )

# Save
saveRDS(rf_cv_gt, here("results", "output", "statistical-analysis", "rf_cv_performance_table.rds"))
gtsave(rf_cv_gt, here("results", "tables", "rf_cv_performance_table.png"), expand = 3)

rf_cv_gt


```

```{r}

# Plot RMSE across combinations
rf_metrics %>% filter(.metric == "rmse") %>%
  ggplot(aes(x = factor(mtry), y = mean, color = factor(min_n))) +
  geom_point(size = 3) +
  geom_line(aes(group = min_n)) +
  labs(title = "Random Forest Tuning Results (RMSE)",
       x = "mtry (Number of Predictors)",
       y = "Mean RMSE",
       color = "min_n") +
  theme_minimal()

```

The lowest cross-validated RMSE (115.2) was observed for the model with mtry = 4 and min_n = 15. RMSE decreased substantially with increasing mtry, while changes in min_n had minimal impact, as seen in the tuning plot.

### 4.2.2 Model Performance

```{r}
# File paths for saving
fit_path       <- here::here("results", "output", "final_rf_fit.rds")
workflow_path  <- here::here("results", "output", "final_rf_workflow.rds")
pred_path      <- here::here("results", "output", "rf_test_predictions.rds")
metrics_path   <- here::here("results", "output", "rf_test_metrics.rds")

# Skip if already saved
if (file.exists(fit_path) && file.exists(pred_path)) {
  message("Final model and predictions already saved. Skipping re-run...")
  final_rf_fit <- readRDS(fit_path)
  final_rf_workflow <- readRDS(workflow_path)
  rf_predictions <- readRDS(pred_path)
  rf_test_metrics <- readRDS(metrics_path)

} else {
  message(" Finalizing and fitting Random Forest model...")

  # Extract best parameters
  best_params <- best_rf_params

  # Finalize the workflow
  final_rf_workflow <- finalize_workflow(rf_workflow, best_params)

  # Fit final model on training set
  set.seed(123)
  final_rf_fit <- fit(final_rf_workflow, data = train_data)

  # Predict on test set
  rf_predictions <- predict(final_rf_fit, new_data = test_data) %>%
    bind_cols(test_data %>% select(mortalities))

  # Evaluate performance
  rf_test_metrics <- rf_predictions %>%
    metrics(truth = mortalities, estimate = .pred)

  # Save all results
  saveRDS(final_rf_fit, file = fit_path)
  saveRDS(final_rf_workflow, file = workflow_path)
  saveRDS(rf_predictions, file = pred_path)
  saveRDS(rf_test_metrics, file = metrics_path)

  message("Final model fit and results saved.")}

# Review metrics
print(rf_test_metrics)

```

The model is performing well, RMSE and MAE both reflect reasonable prediction error magnitudes, with reasonable error and strong explanatory power.

```{r}

# Load saved RF metrics
rf_test_metrics <- readRDS(here::here("results", "output", "rf_test_metrics.rds"))

# Convert to wide format for easy table summary
rf_summary_table <- rf_test_metrics %>%
  select(.metric, .estimate) %>%
  pivot_wider(names_from = .metric, values_from = .estimate) %>%
  mutate(
    Model = "Random Forest",
    Notes = "Tuned with 4 predictors (mtry = 4), min_n = 15") %>%
  select(Model, RMSE = rmse, R2 = rsq, MAE = mae, Notes)

# Save the summary table
invisible(saveRDS(rf_summary_table, here::here("results", "tables", "rf_performance_summary.rds")))

rf_summary_table
```

The final random forest model achieved an RMSE of 115.3, MAE of 66.9, and R² of 0.748 on the test set. These metrics indicate strong predictive accuracy and model fit.

```{r}
# Load predictions
rf_predictions <- readRDS(here("results", "output", "rf_test_predictions.rds"))

# Calculate R² on test set (optional overlay)
r_squared <- cor(rf_predictions$mortalities, rf_predictions$.pred)^2

# Generate the plot
rf_pred_plot <- ggplot(rf_predictions, aes(x = mortalities, y = .pred)) +
  geom_point(alpha = 0.5, color = "#4C78A8", size = 1.2) +
  geom_abline(slope = 1, intercept = 0, linetype = "dashed", color = "gray40") +
  labs(
    title = "Random Forest: Predicted vs. Observed Mortality",
    subtitle = paste0("Test set R² = ", round(r_squared, 3)),
    x = "Observed Mortality Rate (per 100,000)",
    y = "Predicted Mortality Rate (per 100,000)"
  ) +
  theme_minimal(base_size = 14) +
  theme(
    plot.title = element_text(face = "bold", hjust = 0.5),
    plot.subtitle = element_text(hjust = 0.5)
  )

# Save the figure
ggsave(
  here("results", "figures", "rf_pred_vs_obs.png"),
  rf_pred_plot, width = 8, height = 6, dpi = 300)

rf_pred_plot

```

The predicted vs. observed plot shows close alignment with the 45-degree line for most observations, though some spread is visible at higher mortality levels.

### 4.2.3 Variable Importance

Variable importance was assessed using impurity-based measures from the Random Forest model to identify top predictors of county-level mortality.

```{r}
# Load the final fitted model
final_rf_fit <- readRDS(here("results", "output", "final_rf_fit.rds"))

# Extract and clean variable importance
rf_vip_data <- final_rf_fit %>%
  extract_fit_parsnip() %>%
  vi() %>%
  arrange(desc(Importance)) %>%
  slice(1:10) %>%
  mutate(
    CleanLabel = Variable %>%
      str_replace_all("_", " ") %>%
      str_replace_all("\\.", " ") %>%
      str_replace("age group Ages 65  years", "Age Group: 65+ years") %>%
      str_replace("sex Male", "Sex: Male") %>%
      str_replace("sex Female", "Sex: Female") %>%
      str_replace("sex Overall", "Sex: Overall") %>%
      str_replace("race ethnicity Black", "Race: Black") %>%
      str_replace("race ethnicity White", "Race: White") %>%
      str_replace("race ethnicity Hispanic", "Race: Hispanic") %>%
      str_replace("race ethnicity Asian and Pacific Islander", "Race: Asian & Pacific Islander") %>%
      str_replace("race ethnicity American Indian and Alaska Native", "Race: American Indian & Alaska Native") %>%
      str_replace("race ethnicity Overall", "Race: Overall") %>%
      str_squish()
  )

# Create the VIP plot
rf_vip_plot <- ggplot(rf_vip_data, aes(x = Importance, y = fct_reorder(CleanLabel, Importance))) +
  geom_col(fill = "#4C78A8", width = 0.75) +
  labs(
    title = "Random Forest: Variable Importance",
    subtitle = "Top 10 predictors ranked by permutation importance",
    x = "Importance Score",
    y = NULL
  ) +
  theme_minimal(base_size = 14) +
  theme(
    plot.title = element_text(face = "bold", size = 16, hjust = 0.5),
    plot.subtitle = element_text(size = 12, hjust = 0.5),
    axis.text.y = element_text(size = 12)
  )

# Save the plot
ggsave(
  filename = here("results", "figures", "rf_variable_importance.png"),
  plot = rf_vip_plot,
  width = 8,
  height = 7,
  dpi = 300
)

rf_vip_plot
```

Variable importance analysis indicated that age_group_Ages.65.years was by far the most influential predictor in the random forest model. Other variables with moderate contributions included race_ethnicity_Black and race_ethnicity_Hispanic.

A Random Forest model was tuned and evaluated to predict county-level hypertension-related cardiovascular mortality. On the held-out test set, the model achieved an RMSE of 115.3, MAE of 66.9, and R² of 0.748, indicating that it explained approximately 75% of the variance in mortality rates across U.S. counties. These results reflect strong predictive performance and consistency with cross-validation metrics.

This model will serve as a benchmark against which we compare other algorithms, including regularized regression (e.g., LASSO). While random forest provided strong predictive performance, we next evaluated a regularized linear model (LASSO) to assess interpretability and feature selection trade-offs.

### 4.3 LASSO Regression

We next fit a LASSO regression model using the `glmnet` engine. This model applies regularization to reduce overfitting and perform variable selection.

Define the LASSO model specification

```{r}
# LASSO uses glmnet engine with penalty tuning and fixed mixture = 1 (pure LASSO)
lasso_spec <- linear_reg(penalty = tune(), mixture = 1) %>%
  set_engine("glmnet") %>%
  set_mode("regression")


#Create the LASSO workflow
# Workflow with recipe
lasso_workflow <- workflow() %>%
  add_model(lasso_spec) %>%
  add_recipe(mortality_recipe)

```

Tune the penalty using cross-validation

### 4.3.1 Tuning and Coefficients

We tune the penalty parameter (`lambda`) to identify the optimal level of shrinkage. Coefficients from the final model are extracted to assess variable importance.

Creeating a slimmed down version of the tuning RDS file to reduce file size for Github and working with if statements to load this from the correct folder and to not overwrite files.

```{r}
## ---- lasso_tune_and_fit_if_guarded, message=TRUE, warning=FALSE -------------------

# Create folders
dir.create(here::here("results", "output"), showWarnings = FALSE, recursive = TRUE)
dir.create(here::here("results", "large-files"), showWarnings = FALSE, recursive = TRUE)

# Define output paths
lasso_tuned_path        <- here("results", "large-files", "lasso_tuned.rds")
lasso_metrics_path      <- here("results", "output", "lasso_tuned_metrics.rds")
lasso_best_param_path   <- here("results", "output", "lasso_best_params.rds")
lasso_grid_path         <- here("results", "output", "lasso_grid.rds")
slim_lasso_path         <- here("results", "output", "lasso_model_minimal.rds")

# Check if all saved files already exist
if (file.exists(lasso_tuned_path) &&
    file.exists(lasso_metrics_path) &&
    file.exists(lasso_best_param_path) &&
    file.exists(slim_lasso_path)) {

  message("All LASSO files found. Loading saved versions...")

  lasso_tuned <- readRDS(lasso_tuned_path)
  lasso_metrics <- readRDS(lasso_metrics_path)
  best_lasso_params <- readRDS(lasso_best_param_path)
  lasso_slim <- readRDS(slim_lasso_path)
  final_lasso_model <- lasso_slim$model
  lasso_vip <- lasso_slim$vip
  lasso_coeffs <- lasso_slim$coefficients

} else {
  message(" Fitting LASSO model from scratch...")

  # Define grid
  lasso_grid <- grid_regular(penalty(range = c(-4, 0)), levels = 20)
  saveRDS(lasso_grid, lasso_grid_path)

  # Tune
  set.seed(123)
  lasso_tuned <- tune_grid(
    lasso_workflow,
    resamples = cv_folds,
    grid = lasso_grid,
    metrics = metric_set(rmse, rsq, mae),
    control = control_grid(save_pred = TRUE))

  # Extract and save tuning results
  lasso_metrics <- collect_metrics(lasso_tuned)
  best_lasso_params <- select_best(lasso_tuned, metric = "rmse")

  saveRDS(lasso_tuned, lasso_tuned_path)
  saveRDS(lasso_metrics, lasso_metrics_path)
  saveRDS(best_lasso_params, lasso_best_param_path)

  # Finalize and fit
  final_lasso_workflow <- finalize_workflow(lasso_workflow, best_lasso_params)

  set.seed(123)
  final_lasso_model <- fit(final_lasso_workflow, data = train_data)

  # Extract coefficients
  lasso_coeffs <- as.matrix(extract_fit_parsnip(final_lasso_model)$fit$beta)

  # VIP table
  lasso_vip <- tibble(
    variable = rownames(lasso_coeffs),
    importance = abs(lasso_coeffs[, 1])
  ) %>% arrange(desc(importance))

  # Save slimmed version
  saveRDS(
    list(model = final_lasso_model, metrics = lasso_metrics, coefficients = lasso_coeffs, vip = lasso_vip),
    file = slim_lasso_path)

  message("Final LASSO model fitted and slim version saved.")}
```

The slim model can be toggled on or off here by changing from TRUE to FALSE if wanting to use the full version. The full RDS file is saved in the large-files folder which will not automatically upload to github.

```{r}
## ---- lasso_confidence_metrics, message=TRUE, warning=FALSE -------------------

lasso_rmse_summary <- lasso_metrics %>%
  filter(.metric == "rmse") %>%
  mutate(
    lower_95 = mean - 1.96 * std_err,
    upper_95 = mean + 1.96 * std_err
  ) %>%
  arrange(mean)

write.csv(lasso_rmse_summary, here::here("results", "output", "lasso_rmse_summary.csv"), row.names = FALSE)

message("LASSO RMSE summary with CI estimates saved.")
```

```{r}
# Define output path
lasso_cv_rds_path <- here("results", "tables", "lasso_cv_performance_table.rds")

if (file.exists(lasso_cv_rds_path)) {
  message("LASSO CV performance table already exists. Skipping evaluation...")
  lasso_cv_gt_ci <- readRDS(lasso_cv_rds_path)

} else {
  message("Generating LASSO CV performance table from large file...")

  # Load full tuned object
  lasso_tuned <- readRDS(here("results", "large-files", "lasso_tuned.rds"))

  # 1. Collect fold-level predictions and rename for yardstick
  lasso_cv_pred <- collect_predictions(lasso_tuned) %>%
    rename(truth = mortalities)

  # 2. Identify best penalty based on average RMSE across folds
  lasso_cv_best_penalty <- lasso_cv_pred %>%
    group_by(penalty) %>%
    yardstick::rmse(truth = truth, estimate = .pred) %>%
    slice_min(.estimate) %>%
    pull(penalty)
  lasso_cv_best_penalty <- lasso_cv_best_penalty[1]  # ensure scalar

  # 3. Filter only the rows with the selected penalty
  lasso_cv_filtered <- lasso_cv_pred %>%
    filter(penalty == lasso_cv_best_penalty)

  # 4. Loop through folds to compute RMSE and R²
  fold_ids <- unique(lasso_cv_filtered$id)

  lasso_cv_fold_metrics <- lapply(fold_ids, function(fold) {
    fold_data <- lasso_cv_filtered %>% filter(id == fold)
    
    tibble(
      id = fold,
      rmse = yardstick::rmse(fold_data, truth = truth, estimate = .pred)[[".estimate"]],
      rsq  = yardstick::rsq(fold_data, truth = truth, estimate = .pred)[[".estimate"]]
    )
  }) %>%
    bind_rows()

  # 5. Create 95% CI summary table
  lasso_cv_ci_table <- tibble(
    `Selected Penalty` = lasso_cv_best_penalty,
    `RMSE (95% CI)` = sprintf("%.2f [%.2f, %.2f]",
                              mean(lasso_cv_fold_metrics$rmse),
                              mean(lasso_cv_fold_metrics$rmse) - 1.96 * sd(lasso_cv_fold_metrics$rmse),
                              mean(lasso_cv_fold_metrics$rmse) + 1.96 * sd(lasso_cv_fold_metrics$rmse)),
    `R² (95% CI)` = sprintf("%.2f [%.2f, %.2f]",
                            mean(lasso_cv_fold_metrics$rsq),
                            mean(lasso_cv_fold_metrics$rsq) - 1.96 * sd(lasso_cv_fold_metrics$rsq),
                            mean(lasso_cv_fold_metrics$rsq) + 1.96 * sd(lasso_cv_fold_metrics$rsq))
  )

  # 6. Format with gt
  lasso_cv_gt_ci <- lasso_cv_ci_table %>%
    gt() %>%
    tab_header(
      title = md("**LASSO CV Performance Summary**"),
      subtitle = "Mean RMSE and R² with 95% CI across CV folds"
    ) %>%
    tab_options(
      table.font.size = "small",
      table.width = pct(70),
      column_labels.font.weight = "bold",
      data_row.padding = px(3)
    )

  # 7. Save outputs
  saveRDS(lasso_cv_gt_ci, lasso_cv_rds_path)
  gtsave(lasso_cv_gt_ci,
         filename = here("results", "tables", "lasso_cv_performance_table.png"),
         expand = 3)
}

# View (always)
lasso_cv_gt_ci


```

Cross-validation results for the LASSO regression model demonstrated consistent performance across folds. The model achieved a mean RMSE of 119.63 (95% CI: 117.24, 122.02) and an R² of 0.73 (95% CI: 0.72, 0.73), indicating high stability in predictive accuracy and explained variance. These narrow confidence intervals suggest minimal variability across folds, further supporting the robustness and generalizability of the LASSO model when applied to county-level mortality data.

```{r}
#Plot LASSO Tuning Plot
# Plot RMSE vs penalty (log10 scale)
lasso_tune_plot <- lasso_metrics %>%
  filter(.metric == "rmse") %>%
  ggplot(aes(x = penalty, y = mean)) +
  geom_point(size = 2, color = "steelblue") +
  geom_line() +
  scale_x_log10() +
  theme_minimal() +
  labs(title = "LASSO Tuning Results (RMSE vs Penalty)",
       x = "Penalty (log10 scale)",
       y = "Mean RMSE")

# Save to results/figures
invisible(ggsave(filename = here::here("results", "figures", "lasso_tuning_plot.png"),
  plot = lasso_tune_plot,
  width = 7, height = 5, dpi = 300))

lasso_tune_plot
```

LASSO tuning selected a penalty value of approximately 0.0001, minimizing RMSE at \~119.63. Coefficient shrinkage was applied, resulting in the exclusion of several predictors and aiding model interpretability.

### 4.3.2 Model Performance

The final LASSO model is evaluated on the test set and compared to the Random Forest model in terms of predictive accuracy and fit.

```{r}
## Final LASSO Model Fit and Evaluation

# Output paths
lasso_fit_path <- here::here("results", "output", "final_lasso_fit.rds")
lasso_workflow_path <- here::here("results", "output", "final_lasso_workflow.rds")
lasso_pred_path <- here::here("results", "output", "lasso_test_predictions.rds")
lasso_metrics_path <- here::here("results", "output", "lasso_test_metrics.rds")

if (file.exists(lasso_fit_path) &&
    file.exists(lasso_workflow_path) &&
    file.exists(lasso_pred_path) &&
    file.exists(lasso_metrics_path)) {

  message("Loading saved LASSO model and outputs...")
  final_lasso_fit <- readRDS(lasso_fit_path)
  final_lasso_workflow <- readRDS(lasso_workflow_path)
  lasso_test_predictions <- readRDS(lasso_pred_path)
  lasso_test_metrics <- readRDS(lasso_metrics_path)

} else {
  # Finalize model
  final_lasso_workflow <- finalize_workflow(lasso_spec, best_lasso_params)

  # Fit and predict
  final_lasso_fit <- fit(final_lasso_workflow, data = train_data)

  lasso_test_predictions <- predict(final_lasso_fit, new_data = test_data) %>%
    bind_cols(test_data %>% select(mortalities))

  # Evaluate
  lasso_test_metrics <- lasso_test_predictions %>%
    metrics(truth = mortalities, estimate = .pred)

  # Save results
  saveRDS(final_lasso_fit, lasso_fit_path)
  saveRDS(final_lasso_workflow, lasso_workflow_path)
  saveRDS(lasso_test_predictions, lasso_pred_path)
  saveRDS(lasso_test_metrics, lasso_metrics_path)}

# Print metrics
print(lasso_test_metrics)
```

The LASSO model achieved an RMSE of 119.54, MAE of 70.66, and R² of 0.727 on the test set. While performance was slightly below that of the random forest model, LASSO retained strong explanatory power and offers the advantage of interpretability through variable selection.

```{r}
## LASSO: Predicted vs Observed Plot
# Load test predictions
lasso_predictions <- readRDS(here("results", "output", "lasso_test_predictions.rds"))

# Compute R² on test set
lasso_r2 <- cor(lasso_predictions$mortalities, lasso_predictions$.pred)^2

# Create plot
lasso_pred_plot <- ggplot(lasso_predictions, aes(x = mortalities, y = .pred)) +
  geom_point(alpha = 0.4, color = "#4C78A8", size = 1.2) +
  geom_abline(slope = 1, intercept = 0, linetype = "dashed", color = "gray40") +
  labs(
    title = "LASSO Regression: Predicted vs. Observed Mortality",
    subtitle = paste0("Test set R² = ", round(lasso_r2, 3)),
    x = "Observed Mortality Rate (per 100,000)",
    y = "Predicted Mortality Rate (per 100,000)"
  ) +
  theme_minimal(base_size = 14) +
  theme(
    plot.title = element_text(face = "bold", hjust = 0.5),
    plot.subtitle = element_text(hjust = 0.5)
  )

# Save as PNG
ggsave(
  here("results", "figures", "lasso_pred_vs_obs.png"),
  lasso_pred_plot,
  width = 8, height = 6, dpi = 300
)

lasso_pred_plot
```

LASSO is a linear model with regularization — it struggles to capture high-order nonlinear patterns. The horizontal “bands” in predicted values suggest that LASSO may be underfitting in high or low mortality counties. While LASSO remains interpretable, random forest outperforms it in predictive power and flexibility, especially in a dataset with many categorical and potentially non-linear features.

```{r}
lasso_summary_table <- lasso_test_metrics %>%
  select(.metric, .estimate) %>%
  pivot_wider(names_from = .metric, values_from = .estimate) %>%
  mutate(
    Model = "LASSO Regression",
    Notes = paste("Penalty:", signif(best_lasso_params$penalty, 3))
  ) %>%
  select(Model, RMSE = rmse, R2 = rsq, MAE = mae, Notes)

invisible(saveRDS(lasso_summary_table, here::here("results", "tables", "lasso_model_summary.rds")))

lasso_summary_table
```

LASSO regression achieved slightly lower performance than random forest, with an RMSE of \~119.6 and R² of \~0.726indicating a reasonably strong fit for predicting county-level hypertension-related mortality. Compared to the random forest model, LASSO performs slightly worse, but still retains good explanatory power. While LASSO is less flexible than random forest, it offers interpretability through regularization and feature selection. These trade-offs motivate the direct comparison presented in the next section.

Notably, LASSO applies regularization and performs variable selection, meaning it can identify the most influential predictors while shrinking the less important ones to zero. This makes it a useful, interpretable model for identifying risk factors — though it sacrifices some predictive accuracy compared to Random Forest.

### 4.4 Train vs. Test Set Performance

```{r}
# Predict on train data — Random Forest
rf_train_predictions <- predict(final_rf_fit, new_data = train_data) %>%
  bind_cols(train_data %>% select(mortalities))

# Predict on test data — already exists
rf_test_predictions <- readRDS(here("results", "output", "rf_test_predictions.rds"))

# Evaluate
rf_train_metrics <- rf_train_predictions %>%
  metrics(truth = mortalities, estimate = .pred) %>%
  mutate(Model = "Random Forest", Dataset = "Train")

rf_test_metrics <- rf_test_predictions %>%
  metrics(truth = mortalities, estimate = .pred) %>%
  mutate(Model = "Random Forest", Dataset = "Test")

# Predict on train data — LASSO
lasso_train_predictions <- predict(final_lasso_fit, new_data = train_data) %>%
  bind_cols(train_data %>% select(mortalities))

# Predict on test data — already exists
lasso_test_predictions <- readRDS(here("results", "output", "lasso_test_predictions.rds"))

# Evaluate
lasso_train_metrics <- lasso_train_predictions %>%
  metrics(truth = mortalities, estimate = .pred) %>%
  mutate(Model = "LASSO Regression", Dataset = "Train")

lasso_test_metrics <- lasso_test_predictions %>%
  metrics(truth = mortalities, estimate = .pred) %>%
  mutate(Model = "LASSO Regression", Dataset = "Test")

# Combine
train_test_metrics_combined <- bind_rows(
  rf_train_metrics, rf_test_metrics,
  lasso_train_metrics, lasso_test_metrics)

# Format wide
train_test_wide <- train_test_metrics_combined %>%
  select(Model, Dataset, .metric, .estimate) %>%
  tidyr::pivot_wider(names_from = .metric, values_from = .estimate) %>%
  mutate(
    RMSE = sprintf("%.2f", rmse),
    MAE = sprintf("%.2f", mae),
    R2  = sprintf("%.2f", rsq)
  ) %>%
  select(Model, Dataset, RMSE, MAE, R2)

# Build gt table
train_test_performance_table <- train_test_wide %>%
  gt() %>%
  tab_header(
    title = md("**Model Performance: Train vs. Test Set**"),
    subtitle = "Evaluation metrics for Random Forest and LASSO"
  ) %>%
  cols_label(
    RMSE = "RMSE",
    MAE = "MAE",
    R2 = "R²"
  ) %>%
  tab_style(
    style = cell_text(weight = "bold"),
    locations = cells_body(columns = "Model")
  ) %>%
  tab_options(
    table.font.size = "small",
    table.width = pct(100),
    column_labels.font.weight = "bold"
  )

# Save
saveRDS(train_test_performance_table, here("results", "tables", "model_train_test_comparison.rds"))

gtsave(
  train_test_performance_table,
  filename = here("results", "tables", "model_train_test_comparison.png"),
  expand = 5)

# View inline
train_test_performance_table

```

These results indicate that both the Random Forest and LASSO models perform consistently on the training and test datasets, with near-identical RMSE, MAE, and R² values across splits. This suggests that the models are well-tuned and exhibit no signs of overfitting, supporting their generalizability to unseen data.

### 4.5 Model Comparison (Including Null Model)

#### 4.5.1 Null Model (Baseline Performance)

```{r}
# Load train and test data
# train_data and test_data should contain the outcome: mortalities

# 1. Compute the mean outcome in the training data
mean_train_mortality <- mean(train_data$mortalities)

# 2. Create a prediction column in test data
null_predictions <- test_data %>%
  mutate(.pred = mean_train_mortality)

# 3. Calculate performance metrics
null_test_metrics <- null_predictions %>%
  yardstick::metrics(truth = mortalities, estimate = .pred)

# 4. Reformat for consistency with other model outputs
null_summary <- null_test_metrics %>%
  select(.metric, .estimate) %>%
  pivot_wider(names_from = .metric, values_from = .estimate) %>%
  mutate(
    R2 = ifelse(is.na(rsq), NA_real_, rsq),
    Model = "Null Model",
    Notes = "Predicts mean of training set"
  ) %>%
  select(Model, RMSE = rmse, R2 = rsq, MAE = mae, Notes)

# Save to use in table if desired
saveRDS(null_summary, here::here("results", "output", "null_model_summary.rds"))

# preview
null_summary

```

Note: The null model does not produce a valid R² because it predicts a constant value, resulting in undefined correlation.

#### 4.5.2 LASSO and RF Model Comparison

Comnparing model performance metrics between LASSO and RF. Generating a model comparison table:

```{r}
# Load saved test metrics
rf_test_metrics <- readRDS(here("results", "output", "rf_test_metrics.rds"))
lasso_test_metrics <- readRDS(here("results", "output", "lasso_test_metrics.rds"))

# Summarize RF
rf_summary <- rf_test_metrics %>%
  select(.metric, .estimate) %>%
  pivot_wider(names_from = .metric, values_from = .estimate) %>%
  mutate(
    Model = "Random Forest",
    Notes = "Tuned (mtry = 4, min_n = 15)"
  ) %>%
  select(Model, RMSE = rmse, R2 = rsq, MAE = mae, Notes)

# Summarize LASSO
lasso_summary <- lasso_test_metrics %>%
  select(.metric, .estimate) %>%
  pivot_wider(names_from = .metric, values_from = .estimate) %>%
  mutate(
    Model = "LASSO Regression",
    Notes = "Penalty = 0.1"
  ) %>%
  select(Model, RMSE = rmse, R2 = rsq, MAE = mae, Notes)

# Combine summaries
model_summary <- bind_rows(rf_summary, lasso_summary)

# Create polished gt table
model_performance_summary_table <- model_summary %>%
  gt() %>%
  tab_header(
    title = md("**Model Performance Summary**"),
    subtitle = "Held-out test set evaluation for Random Forest and LASSO"
  ) %>%
  fmt_number(columns = c(RMSE, R2, MAE), decimals = 2) %>%
  cols_label(
    RMSE = "RMSE",
    R2 = "R²",
    MAE = "MAE",
    Notes = "Model Details"
  ) %>%
  tab_options(
    table.font.size = "small",
    data_row.padding = px(4),
    table.width = pct(100))

# Save as RDS
saveRDS(model_performance_summary_table, here("results", "tables", "model_performance_summary.rds"))

# Save as PNG
gtsave(data = model_performance_summary_table,
  filename = here("results", "tables", "model_performance_summary.png"),
  expand = 5)

# Also save numeric summary (wide format)
saveRDS(model_summary, here("results", "output", "model_performance_numeric.rds"))


model_performance_summary_table
```

To directly compare model performance, we generated side-by-side summaries of RMSE, R², and MAE for both random forest and LASSO regression using the test dataset.

Random forest outperformed LASSO on all metrics, with lower RMSE (115.3 vs. 119.5), lower MAE (66.9 vs. 70.7), and higher R² (0.748 vs. 0.727). While both models demonstrated good predictive accuracy, random forest offered stronger overall performance.

#### 4.4.3 Comparing the LASSO and RF models to the Null model

```{r}
# Format RF
rf_metrics_for_null <- rf_test_metrics %>%
  select(.metric, .estimate) %>%
  pivot_wider(names_from = .metric, values_from = .estimate) %>%
  mutate(Model = "Random Forest")

# Format LASSO
lasso_metrics_for_null <- lasso_test_metrics %>%
  select(.metric, .estimate) %>%
  pivot_wider(names_from = .metric, values_from = .estimate) %>%
  mutate(Model = "LASSO Regression")

# Format Null
null_metrics_for_null <- null_summary %>%
  mutate(Model = "Null Model") %>%
  select(Model, RMSE, R2, MAE)

# Combine with MAE before R2
model_comparison_null_data <- bind_rows(
  rf_metrics_for_null %>% select(Model, RMSE = rmse, MAE = mae, R2 = rsq),
  lasso_metrics_for_null %>% select(Model, RMSE = rmse, MAE = mae, R2 = rsq),
  null_metrics_for_null %>% select(Model, RMSE, MAE, R2)
)

# Format as strings for clean spacing
model_comparison_null_table <- model_comparison_null_data %>%
  mutate(
    RMSE = sprintf("%.2f", RMSE),
    MAE  = sprintf("%.2f", MAE),
    R2   = ifelse(is.na(R2), "–", sprintf("%.2f", R2))
  ) %>%
  gt() %>%
  tab_header(
    title = md("**Model Comparison Including Null Model**"),
    subtitle = "Performance on held-out test set"
  ) %>%
  cols_label(
    RMSE = "RMSE",
    MAE  = "MAE",
    R2   = "R²"
  ) %>%
  tab_options(
    table.font.size = "small",
    data_row.padding = px(4),
    table.width = pct(100),
    column_labels.font.weight = "bold"
  )

# Save
saveRDS(model_comparison_null_table, here("results", "output", "statistical-analysis", "model_null_comparison_table.rds"))

gtsave(model_comparison_null_table,
       filename = here("results", "tables", "model_null_comparison_table.png"),
       expand = 5)

model_comparison_null_table
```

Reproducing the table for the manuscript:

```{r}
# 1. RF Summary for null-inclusive table
null_comparison_rf_summary <- rf_test_metrics %>%
  select(.metric, .estimate) %>%
  tidyr::pivot_wider(names_from = .metric, values_from = .estimate) %>%
  mutate(
    Model = "Random Forest",
    Notes = "Tuned (mtry = 4, min_n = 15)"
  ) %>%
  select(Model, RMSE = rmse, R2 = rsq, MAE = mae, Notes)

# 2. LASSO Summary for null-inclusive table
null_comparison_lasso_summary <- lasso_test_metrics %>%
  select(.metric, .estimate) %>%
  tidyr::pivot_wider(names_from = .metric, values_from = .estimate) %>%
  mutate(
    Model = "LASSO Regression",
    Notes = "Penalty = 0.1"
  ) %>%
  select(Model, RMSE = rmse, R2 = rsq, MAE = mae, Notes)

# 3. Null model summary for table
null_comparison_null_summary <- null_summary %>%
  mutate(
    Model = "Null Model",
    R2 = NA_real_,
    Notes = "Predicts mean of training set"
  ) %>%
  select(Model, RMSE, R2, MAE, Notes)

# 4. Combine rows into single summary
null_comparison_summary_all <- bind_rows(
  null_comparison_rf_summary,
  null_comparison_lasso_summary,
  null_comparison_null_summary
)

# 5. Create gt table
null_comparison_gt_table <- null_comparison_summary_all %>%
  mutate(
    RMSE = sprintf("%.2f", RMSE),
    MAE  = sprintf("%.2f", MAE),
    R2   = ifelse(is.na(R2), "–", sprintf("%.2f", R2))
  ) %>%
  select(Model, RMSE, MAE, R2, Notes) %>%
  gt() %>%
  tab_header(
    title = md("**Model Performance Summary**"),
    subtitle = "Held-out test set evaluation for Random Forest, LASSO, and Null Model"
  ) %>%
  cols_label(
    RMSE = "RMSE",
    MAE  = "MAE",
    R2   = "R²",
    Notes = "Model Details"
  ) %>%
  tab_style(
    style = cell_text(weight = "bold"),
    locations = cells_body(columns = "Model")
  ) %>%
  tab_options(
    table.font.size = "14",
    data_row.padding = px(3),
    table.width = pct(65),
    column_labels.font.weight = "bold"
  )


# 6. Save outputs
saveRDS(null_comparison_gt_table, here("results", "output", "statistical-analysis", "final_model_performance_table.rds"))

gtsave(
  data = null_comparison_gt_table,
  filename = here("results", "tables", "final_model_performance_table.png"),
  expand = 3
)

# 7. Save raw data
saveRDS(null_comparison_summary_all, here("results", "output", "statistical-analysis", "model_performance_with_null_numeric.rds"))

# View table
null_comparison_gt_table

```

4.4.3 Null Model Comparison To contextualize model performance, a null model was included that predicted the mean training set mortality rate for all test observations. This baseline yielded substantially higher error metrics, with an RMSE of 228.65 and a mean absolute error (MAE) of 192.28. As expected, R² was undefined for the null model due to its constant prediction, which results in zero variance. In contrast, both the Random Forest (RMSE = 115.30; R² = 0.75) and LASSO regression (RMSE = 119.54; R² = 0.73) models significantly outperformed the null model across all metrics. This confirms that even the more constrained linear model (LASSO) captured meaningful structure in the data beyond what could be explained by the overall average alone.

Aim 4 Summary: We compared two predictive models for county-level hypertension-related CVD mortality: a random forest model and a LASSO regression model. The random forest achieved the best performance, with an RMSE of 115.3 and R² of 0.748 on the test set. LASSO regression performed slightly worse (RMSE = 119.6, R² = 0.726) but offers the benefit of interpretability through feature selection. These results indicate strong overall predictive performance, with random forest serving as the best-performing model. Both models demonstrated solid predictive performance, with random forest performing best. The structured pattern seen in the predicted vs observed plots reflects the nature of the input data — with many counties having identical values for categorical groupings. The use of dummy variables, while necessary, introduces constraints that can create repeated predictions for common demographic combinations, especially in linear models like LASSO. This highlights a trade-off between model interpretability and flexibility.
